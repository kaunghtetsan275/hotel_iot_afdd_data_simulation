<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>agent API documentation</title>
<meta name="description" content="Simulation agent ‚Ä¶">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Package <code>agent</code></h1>
</header>
<section id="section-intro">
<p>Simulation agent.</p>
<p>A simulator for Indoor Air Quality (IAQ) sensors that generates and publishes simulated sensor data
to RabbitMQ and Supabase. This class supports advanced data generation for temperature, humidity,
CO2 levels, occupancy, and power consumption, and provides methods for publishing data to RabbitMQ
and Supabase.</p>
<p>Fault Detection Agent </p>
<p>Designed to facilitate fault detection in IoT-based hotel systems.
It integrates with various services such as RabbitMQ, Supabase, and TimescaleDB to process sensor
data, detect anomalies, and publish alerts. The class provides methods for initializing database
connections, managing RabbitMQ exchanges and queues, subscribing to real-time updates, and
detecting faults based on predefined or dynamically updated thresholds.</p>
<p>Key Features:
- Connects to TimescaleDB for storing and querying sensor data.
- Integrates with RabbitMQ for message consumption and alert publishing.
- Uses Supabase for managing fault thresholds and storing fault status.
- Supports real-time subscription to threshold updates via Supabase.
- Detects faults in indoor air quality (IAQ), power consumption, and occupancy sensors.
- Publishes alerts to RabbitMQ and Supabase when faults are detected.
- Provides default and customizable fault thresholds for various sensor types.
This class is designed to run continuously, consuming sensor data, detecting faults, and
publishing alerts in real-time, making it suitable for IoT-based fault detection systems.</p>
</section>
<section>
<h2 class="section-title" id="header-submodules">Sub-modules</h2>
<dl>
<dt><code class="name"><a title="agent.agent_fault_detection" href="agent_fault_detection.html">agent.agent_fault_detection</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="agent.agent_simulation" href="agent_simulation.html">agent.agent_simulation</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="agent.FaultDetectionAgent"><code class="flex name class">
<span>class <span class="ident">FaultDetectionAgent</span></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class FaultDetectionAgent:
    def __init__(self):
        # Configure logging
        logging.basicConfig(level=logging.INFO, format=&#39;%(asctime)s - %(levelname)s - %(message)s&#39;)
        # Silence Supabase Realtime logs
        logging.getLogger(&#34;pika&#34;).setLevel(logging.WARNING)
        logging.getLogger(&#39;realtime&#39;).setLevel(logging.WARNING)
        logging.getLogger(&#39;realtime._async.client&#39;).setLevel(logging.WARNING)
        logging.getLogger(&#39;realtime._async.channel&#39;).setLevel(logging.WARNING)
        # Optionally, silence other related loggers
        logging.getLogger(&#39;httpx&#39;).setLevel(logging.WARNING)
        logging.getLogger(&#39;asyncio&#39;).setLevel(logging.WARNING)
        logging.getLogger(&#39;phx_websocket&#39;).setLevel(logging.WARNING)
        logging.getLogger(&#39;phoenix&#39;).setLevel(logging.WARNING)
        logging.getLogger(&#39;websockets&#39;).setLevel(logging.WARNING)

        # RabbitMQ connection parameters
        self.RABBITMQ_URL = f&#34;amqp://{config(&#39;RABBITMQ_USER&#39;)}:{config(&#39;RABBITMQ_PASSWORD&#39;)}@{config(&#39;RABBITMQ_HOST&#39;)}:{config(&#39;RABBITMQ_PORT&#39;)}/&#34;
        self.RABBITMQ_HOST = config(&#39;RABBITMQ_HOST&#39;)
        self.EXCHANGE_NAME = config(&#39;EXCHANGE_NAME&#39;, default=&#39;hotel_iot&#39;)
        self.ALERT_EXCHANGE_NAME = config(&#39;ALERT_EXCHANGE_NAME&#39;, default=&#39;fault_alerts&#39;)

        # Initialize Supabase client
        self.SUPABASE_URL = config(&#39;SUPABASE_URL&#39;)
        self.SUPABASE_API_KEY = config(&#39;SUPABASE_API_KEY&#39;)
        self.supabase = create_client(self.SUPABASE_URL, self.SUPABASE_API_KEY)

        self.fault_thresholds = {} # Global variable to store current thresholds
        self.last_occupied = {} # In-memory state to track last occupancy time (for stuck occupied detection)

        # TimescaleDB connection
        self.DB_NAME = config(&#39;TIMESCALEDB_DATABASE&#39;)
        self.DB_USER = config(&#39;TIMESCALEDB_USER&#39;)
        self.DB_PASSWORD = config(&#39;TIMESCALEDB_PASSWORD&#39;)
        self.DB_PORT = config(&#39;TIMESCALEDB_PORT&#39;, default=&#39;5432&#39;)
        self.DB_HOST = config(&#39;TIMESCALEDB_HOST&#39;)


    def init_db_connection(self):
        self.conn = psycopg2.connect(
            dbname=self.DB_NAME,
            user=self.DB_USER,
            password=self.DB_PASSWORD,
            host=self.DB_HOST,
            port=self.DB_PORT
        )
        self.cursor = self.conn.cursor()

        # Check if table named raw_data exists
        self.cursor.execute(&#34;SELECT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_name = &#39;raw_data&#39;)&#34;)
        if self.cursor.fetchone()[0]:
            logging.info(&#34;üëæ TimescaleDB table &#39;raw_data&#39; exists.&#34;)
        else:
            logging.info(&#34;üëæ TimescaleDB table &#39;raw_data&#39; does not exist. Creating it...&#34;)
            self.cursor.execute(&#34;&#34;&#34;
                CREATE TABLE raw_data (
                    id SERIAL PRIMARY KEY,
                    timestamp BIGINT NOT NULL,
                    datetime TIMESTAMP NOT NULL,
                    device_id VARCHAR(50) NOT NULL,
                    datapoint VARCHAR(50) NOT NULL,
                    value TEXT NOT NULL,
                    did INTEGER
                )
            &#34;&#34;&#34;)
            self.conn.commit()
            logging.info(&#34;üëæ TimescaleDB table &#39;raw_data&#39; created.&#34;)

    def init_rabbitmq_connection(self) -&gt; None:
        &#34;&#34;&#34;
        Initializes the RabbitMQ connection and sets up the exchange channel.
        &#34;&#34;&#34;
        # RabbitMQ connection
        self.connection = pika.BlockingConnection(pika.ConnectionParameters(self.RABBITMQ_HOST))
        self.channel = self.connection.channel()
        self.exchange = self.channel.exchange_declare(exchange=self.ALERT_EXCHANGE_NAME, exchange_type=&#39;topic&#39;)


    def insert_row_data(self, data) -&gt; None:
        &#34;&#34;&#34;
        Inserts processed row data into the raw_data database table.
        &#34;&#34;&#34;
        insert_queries = []
        skipped_keys = [&#39;datetime&#39;, &#39;device_id&#39;, &#39;id&#39;, &#39;sensor_type&#39;]
        timestamp = data[&#34;datetime&#34;]
        
        for key in data.keys():
            if key in skipped_keys:
                continue
            insert_queries.append((
                int(datetime.fromisoformat(timestamp).timestamp()),
                datetime.fromisoformat(timestamp),
                data[&#34;device_id&#34;],
                key,
                str(data[key]),
                data[&#34;id&#34;]
            ))

        self.cursor.executemany(
            &#34;&#34;&#34;
            INSERT INTO raw_data (timestamp, datetime, device_id, datapoint, value, did)
            VALUES (%s, %s, %s, %s, %s, %s)
            &#34;&#34;&#34;,
            insert_queries
        )
        self.conn.commit()

    def process_and_insert_data(self, data: Dict[str, Any]) -&gt; None:
        &#34;&#34;&#34;
        Processes incoming data and inserts it into the database if valid.
        &#34;&#34;&#34;
        if not data.get(&#34;datetime&#34;):
            logging.info(&#34; [!] No timestamp found in data.&#34;)
            return
        try:
            self.insert_row_data(data)
        except (TypeError, ValueError):
            logging.error(&#34; [!] Invalid IAQ sensor data received. Non-numeric values detected.&#34;)
            return
        except Exception as e:
            logging.error(f&#34; [!] Error inserting data into TimescaleDB: {e}&#34;)
            return

    def get_default_thresholds(self) -&gt; dict:
        &#34;&#34;&#34;Retrieve the default thresholds.&#34;&#34;&#34;
        return {
            &#39;iaq&#39;: {
                &#39;temperature_low&#39;: 18,
                &#39;temperature_high&#39;: 26,
                &#39;humidity_low&#39;: 30,
                &#39;humidity_high&#39;: 60,
                &#39;co2_low&#39;: 400,
                &#39;co2_high&#39;: 1000
            },
            &#39;power&#39;: {
                &#39;power_spike_threshold&#39;: 1
            },
            &#39;occupancy&#39;: {
                &#39;stuck_occupied_timeout&#39;: 24
            }
        }

    def get_initial_thresholds(self) -&gt; dict:
        &#34;&#34;&#34;
        Retrieve initial fault detection thresholds from Supabase or use defaults.
        &#34;&#34;&#34;
        response = self.supabase.table(&#39;fault_thresholds&#39;).select(&#39;*&#39;).execute()
        if response.data:
            logging.info(&#34;üëæ Read thresholds from Supabase&#34;)
            return self.process_threshold_data(response.data[0])
        else:
            return self.get_default_thresholds()

    def process_threshold_data(self, record: dict) -&gt; dict:
        &#34;&#34;&#34;
        Processes threshold data from a record dictionary into a structured format.
        &#34;&#34;&#34;
        return {
            &#39;iaq&#39;: {
                &#39;temperature_low&#39;: record.get(&#39;temperature_min&#39;),
                &#39;temperature_high&#39;: record.get(&#39;temperature_max&#39;),
                &#39;humidity_low&#39;: record.get(&#39;humidity_min&#39;),
                &#39;humidity_high&#39;: record.get(&#39;humidity_max&#39;),
                &#39;co2_low&#39;: record.get(&#39;co2_min&#39;),
                &#39;co2_high&#39;: record.get(&#39;co2_max&#39;)
            },
            &#39;power&#39;: {
                &#39;power_spike_threshold&#39;: record.get(&#39;power_kw_max&#39;)
            },
            &#39;occupancy&#39;: {
                &#39;stuck_occupied_timeout&#39;: record.get(&#39;sensitivity_max&#39;)
            }
        }

    async def setup_realtime_subscription(self) -&gt; None:
        &#34;&#34;&#34;
        Sets up a realtime subscription to monitor and handle table changes.
        &#34;&#34;&#34;
        async_client = await create_async_client(config(&#39;SUPABASE_URL&#39;), config(&#39;SUPABASE_API_KEY&#39;))

        def handle_change(payload):
            logging.info(&#34;üëæ Threshold updated from somewhere else!&#34;)
            if payload[&#39;event_type&#39;] in (&#39;INSERT&#39;, &#39;UPDATE&#39;):
                self.fault_thresholds = self.process_threshold_data(payload[&#39;new&#39;])
            elif payload[&#39;event_type&#39;] == &#39;DELETE&#39;:
                self.fault_thresholds = self.get_default_thresholds()

        channel = await async_client.channel(&#39;threshold_changes&#39;)\
            .on_postgres_changes(
                event=&#39;UPDATE&#39;,
                schema=&#39;public&#39;,
                table=&#39;fault_thresholds&#39;,
                callback=handle_change
            ).subscribe()
        logging.info(f&#34;üëæ[‚úì] Realtime subscription active for threshold values. {async_client.realtime.is_connected}&#34;)
        while True:
            await asyncio.sleep(3600)

    def get_queues_for_exchange(self) -&gt; list:
        &#34;&#34;&#34;
        Retrieve the list of queue names bound to a specific RabbitMQ exchange.
        &#34;&#34;&#34;
        rabbitmq_host = config(&#39;RABBITMQ_HOST&#39;)
        url = f&#39;http://{rabbitmq_host}:15672/api/bindings&#39;
        response = requests.get(url, auth=HTTPBasicAuth(&#39;guest&#39;, &#39;guest&#39;))
        
        if response.status_code == 200:
            bindings = response.json()
            queues = [
                binding[&#39;destination&#39;]
                for binding in bindings
                if binding[&#39;source&#39;] == config(&#39;EXCHANGE_NAME&#39;) and binding[&#39;destination_type&#39;] == &#39;queue&#39;
            ]
            return queues
        else:
            logging.error(f&#34;Failed to fetch bindings: {response.status_code}&#34;)
            return []
    
    def run_fault_detection(self) -&gt; None:
        &#34;&#34;&#34;
        Listens for sensor data messages and performs fault detection.
        &#34;&#34;&#34;
        channel = self.connection.channel()
        channel.exchange_declare(exchange=self.EXCHANGE_NAME, exchange_type=&#39;topic&#39;, durable=True)

        result = channel.queue_declare(queue=&#39;&#39;, durable=True, exclusive=True)
        queue_name = result.method.queue
        channel.queue_bind(exchange=self.EXCHANGE_NAME, queue=queue_name, routing_key=&#39;#&#39;)

        logging.info(&#34;üëæüêá Waiting for sensor data...&#34;)

        def callback(ch, method, properties, body):
            try:
                data = json.loads(body.decode())
                self.detect_faults(data, method.routing_key)
            except Exception as e:
                logging.error(&#34;[!] Error processing message:&#34;, e)
        channel.basic_consume(queue=queue_name, on_message_callback=callback, auto_ack=True)
        channel.start_consuming()

    def detect_faults(self, sensor_data, queue_name) -&gt; None:
        &#34;&#34;&#34;
        Detects faults in sensor data and publishes alerts if thresholds are exceeded.
        Args:
            sensor_data (dict): A dictionary containing sensor data. Expected keys include:
                - &#39;id&#39; (str): The unique identifier for the data.
                - &#39;device_id&#39; (str): The unique identifier for the device.
                - &#39;sensor_type&#39; (str): The type of sensor (e.g., &#39;temperature&#39;, &#39;humidity&#39;, &#39;co2&#39;, &#39;power_meter&#39;, etc.).
                - &#39;datetime&#39; (str): The timestamp of the sensor data in ISO 8601 format.
                - Additional keys depending on the sensor type (e.g., &#39;temperature&#39;, &#39;humidity&#39;, &#39;co2&#39;, &#39;power_meter&#39;, &#39;occupancy&#39;).
            queue_name (str): The name of the queue to which alerts should be published.
        Returns:
            None
        Behavior:
            - For &#39;temperature&#39;, &#39;humidity&#39;, and &#39;co2&#39; sensors:
                - Checks if the values exceed predefined thresholds for indoor air quality (IAQ).
                - Publishes alerts for high or low temperature, humidity, or high CO2 levels.
                - Processes and inserts the sensor data, marking whether an IAQ fault was detected.
            - For &#39;power_meter&#39; sensors:
                - Detects power spikes based on a predefined threshold.
                - Publishes alerts for power spikes.
                - Processes and inserts the sensor data, marking whether a power fault was detected.
            - For &#39;online_status&#39;, &#39;occupancy_status&#39;, and &#39;sensitivity&#39; sensors:
                - Tracks room occupancy states and timestamps.
                - Detects if a room has been marked as occupied for too long, indicating a potential sensor issue.
                - Publishes alerts for stuck occupancy states.
                - Processes and inserts the sensor data, marking whether an occupancy fault was detected.
            - Logs warnings if incomplete sensor data is received.
        &#34;&#34;&#34;
        did = sensor_data.get(&#39;id&#39;)
        device_id = sensor_data.get(&#39;device_id&#39;)
        sensor_type = sensor_data.get(&#39;sensor_type&#39;)
        timestamp = sensor_data.get(&#39;datetime&#39;)

        if not all([device_id, timestamp]):
            logging.warning(&#34; [!] Incomplete sensor data received.&#34;)
            return

        if sensor_type in [&#39;temperature&#39;, &#39;humidity&#39;, &#39;co2&#39;]:
            iaq_fault = False
            temperature = sensor_data.get(&#39;temperature&#39;)
            humidity = sensor_data.get(&#39;humidity&#39;)
            co2 = sensor_data.get(&#39;co2&#39;)

            if temperature is not None:
                if temperature &gt; self.fault_thresholds[&#39;iaq&#39;][&#39;temperature_high&#39;]:
                    self.publish_alert(queue_name, device_id, did, &#39;temperature_high&#39;, f&#39;Temperature {temperature}¬∞C exceeds threshold {self.fault_thresholds[&#34;iaq&#34;][&#34;temperature_high&#34;]}¬∞C&#39;, timestamp)
                elif temperature &lt; self.fault_thresholds[&#39;iaq&#39;][&#39;temperature_low&#39;]:
                    self.publish_alert(queue_name, device_id, did, &#39;temperature_low&#39;, f&#39;Temperature {temperature}¬∞C is below threshold {self.fault_thresholds[&#34;iaq&#34;][&#34;temperature_low&#34;]}¬∞C&#39;, timestamp)
            if humidity is not None:
                if humidity &gt; self.fault_thresholds[&#39;iaq&#39;][&#39;humidity_high&#39;]:
                    self.publish_alert(queue_name, device_id, did, &#39;humidity_high&#39;, f&#39;Humidity {humidity}% exceeds threshold {self.fault_thresholds[&#34;iaq&#34;][&#34;humidity_high&#34;]}%&#39;, timestamp)
                elif humidity &lt; self.fault_thresholds[&#39;iaq&#39;][&#39;humidity_low&#39;]:
                    self.publish_alert(queue_name, device_id, did, &#39;humidity_low&#39;, f&#39;Humidity {humidity}% is below threshold {self.fault_thresholds[&#34;iaq&#34;][&#34;humidity_low&#34;]}%&#39;, timestamp)
            if co2 is not None:
                if co2 &gt; self.fault_thresholds[&#39;iaq&#39;][&#39;co2_high&#39;]:
                    self.publish_alert(queue_name, device_id, did, &#39;co2_high&#39;, f&#39;CO2 level {co2} ppm exceeds threshold {self.fault_thresholds[&#34;iaq&#34;][&#34;co2_high&#34;]} ppm&#39;, timestamp)
            self.process_and_insert_data(sensor_data)

        elif sensor_type == &#39;power_meter&#39;:
            power_meter = sensor_data.get(&#39;power_meter&#39;)
            if power_meter is not None:
                # Simple power spike detection (can be enhanced with moving averages etc.)
                if power_meter &gt; self.fault_thresholds[&#39;power&#39;][&#39;power_spike_threshold&#39;]:
                    self.publish_alert(queue_name, device_id, did, &#39;power_spike&#39;, f&#39;Power consumption spiked to {power_meter} kW on device {device_id}&#39;, timestamp)
            self.process_and_insert_data(sensor_data)

        elif sensor_type in [&#39;online_status&#39;, &#39;occupancy_status&#39;, &#39;sensitivity&#39;]:
            room_id = device_id.split(&#39;-&#39;)[2]
            occupancy_state = sensor_data.get(&#39;occupancy&#39;)
            if occupancy_state == &#39;occupied&#39;:
                self.last_occupied[room_id] = datetime.strptime(timestamp, &#39;%Y-%m-%dT%H:%M:%S.%f&#39;)
            elif occupancy_state == &#39;unoccupied&#39; and room_id in self.last_occupied:
                del self.last_occupied[room_id] # Reset if unoccupied

            # Detect if a room has been occupied for too long (potential sensor issue)
            if room_id in self.last_occupied:
                if (datetime.now() - self.last_occupied[room_id]).total_seconds() &gt; self.fault_thresholds[&#39;occupancy&#39;][&#39;stuck_occupied_timeout&#39;] * 3600:
                    self.publish_alert(queue_name, device_id, did, &#39;stuck_occupied&#39;, f&#39;Room has been occupied since {self.last_occupied[room_id]}&#39;, timestamp)
            self.process_and_insert_data(sensor_data)

    def publish_to_rabbitmq(self, queue_name, alert_data) -&gt; None:
        &#34;&#34;&#34;
        Publishes alert data to a RabbitMQ queue.

        This method declares a queue with the specified queue name, binds it to the
        alert exchange using the routing key, and publishes the alert data to the queue.

        Args:
            queue_name (str): The name of the queue to publish the alert data to.
            alert_data (dict): The alert data to be published. It will be serialized to JSON format.

        Raises:
            pika.exceptions.AMQPError: If there is an error during queue declaration, binding, or publishing.
        &#34;&#34;&#34;
        routing_key = f&#39;_{queue_name}&#39;
        self.channel.queue_declare(queue=routing_key)
        self.channel.queue_bind(exchange=self.ALERT_EXCHANGE_NAME, queue=routing_key, routing_key=routing_key)
        self.channel.basic_publish(exchange=self.ALERT_EXCHANGE_NAME, routing_key=routing_key, body=json.dumps(alert_data))

    def publish_to_supabase(self, alert_data) -&gt; None:
        &#34;&#34;&#34;
        Publishes alert data to the Supabase table.

        Args:
            alert_data (dict): A dictionary containing the alert data to be published.

        Returns:
            None
        &#34;&#34;&#34;
        try:
            response = self.supabase.table(&#39;fault_status&#39;).insert(alert_data).execute()
        except Exception as e:
            logging.error(f&#34; [!] Error publishing to Supabase: {e}&#34;)
            return

    def publish_alert(self,  queue_name, device_id, did, fault_type, message, timestamp) -&gt; None:
        &#34;&#34;&#34;
        Publishes an alert to RabbitMQ and Supabase.

        This method sends an alert message containing fault details to a specified
        RabbitMQ queue and also stores the alert data in Supabase for further processing
        or record-keeping.

        Args:
            queue_name (str): The name of the RabbitMQ queue to publish the alert to.
            device_id (str): The unique identifier of the device where the fault occurred.
            did (str): The unique identifier for the detection instance.
            fault_type (str): The type of fault detected (e.g., &#34;temperature_fault&#34;).
            message (str): A descriptive message providing details about the fault.
            timestamp (str): The timestamp when the fault was detected.

        Returns:
            None
        &#34;&#34;&#34;
        alert_data = {
            &#39;device_id&#39;: device_id,
            &#39;fault_type&#39;: fault_type,
            &#39;status&#39;: &#39;open&#39;,
            &#39;message&#39;: message,
            &#39;detected_at&#39;: timestamp,
            &#39;did&#39;: did,
        }
        self.publish_to_rabbitmq(queue_name, alert_data)
        self.publish_to_supabase(alert_data)</code></pre>
</details>
<div class="desc"></div>
<h3>Methods</h3>
<dl>
<dt id="agent.FaultDetectionAgent.detect_faults"><code class="name flex">
<span>def <span class="ident">detect_faults</span></span>(<span>self, sensor_data, queue_name) ‚Äë>¬†None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def detect_faults(self, sensor_data, queue_name) -&gt; None:
    &#34;&#34;&#34;
    Detects faults in sensor data and publishes alerts if thresholds are exceeded.
    Args:
        sensor_data (dict): A dictionary containing sensor data. Expected keys include:
            - &#39;id&#39; (str): The unique identifier for the data.
            - &#39;device_id&#39; (str): The unique identifier for the device.
            - &#39;sensor_type&#39; (str): The type of sensor (e.g., &#39;temperature&#39;, &#39;humidity&#39;, &#39;co2&#39;, &#39;power_meter&#39;, etc.).
            - &#39;datetime&#39; (str): The timestamp of the sensor data in ISO 8601 format.
            - Additional keys depending on the sensor type (e.g., &#39;temperature&#39;, &#39;humidity&#39;, &#39;co2&#39;, &#39;power_meter&#39;, &#39;occupancy&#39;).
        queue_name (str): The name of the queue to which alerts should be published.
    Returns:
        None
    Behavior:
        - For &#39;temperature&#39;, &#39;humidity&#39;, and &#39;co2&#39; sensors:
            - Checks if the values exceed predefined thresholds for indoor air quality (IAQ).
            - Publishes alerts for high or low temperature, humidity, or high CO2 levels.
            - Processes and inserts the sensor data, marking whether an IAQ fault was detected.
        - For &#39;power_meter&#39; sensors:
            - Detects power spikes based on a predefined threshold.
            - Publishes alerts for power spikes.
            - Processes and inserts the sensor data, marking whether a power fault was detected.
        - For &#39;online_status&#39;, &#39;occupancy_status&#39;, and &#39;sensitivity&#39; sensors:
            - Tracks room occupancy states and timestamps.
            - Detects if a room has been marked as occupied for too long, indicating a potential sensor issue.
            - Publishes alerts for stuck occupancy states.
            - Processes and inserts the sensor data, marking whether an occupancy fault was detected.
        - Logs warnings if incomplete sensor data is received.
    &#34;&#34;&#34;
    did = sensor_data.get(&#39;id&#39;)
    device_id = sensor_data.get(&#39;device_id&#39;)
    sensor_type = sensor_data.get(&#39;sensor_type&#39;)
    timestamp = sensor_data.get(&#39;datetime&#39;)

    if not all([device_id, timestamp]):
        logging.warning(&#34; [!] Incomplete sensor data received.&#34;)
        return

    if sensor_type in [&#39;temperature&#39;, &#39;humidity&#39;, &#39;co2&#39;]:
        iaq_fault = False
        temperature = sensor_data.get(&#39;temperature&#39;)
        humidity = sensor_data.get(&#39;humidity&#39;)
        co2 = sensor_data.get(&#39;co2&#39;)

        if temperature is not None:
            if temperature &gt; self.fault_thresholds[&#39;iaq&#39;][&#39;temperature_high&#39;]:
                self.publish_alert(queue_name, device_id, did, &#39;temperature_high&#39;, f&#39;Temperature {temperature}¬∞C exceeds threshold {self.fault_thresholds[&#34;iaq&#34;][&#34;temperature_high&#34;]}¬∞C&#39;, timestamp)
            elif temperature &lt; self.fault_thresholds[&#39;iaq&#39;][&#39;temperature_low&#39;]:
                self.publish_alert(queue_name, device_id, did, &#39;temperature_low&#39;, f&#39;Temperature {temperature}¬∞C is below threshold {self.fault_thresholds[&#34;iaq&#34;][&#34;temperature_low&#34;]}¬∞C&#39;, timestamp)
        if humidity is not None:
            if humidity &gt; self.fault_thresholds[&#39;iaq&#39;][&#39;humidity_high&#39;]:
                self.publish_alert(queue_name, device_id, did, &#39;humidity_high&#39;, f&#39;Humidity {humidity}% exceeds threshold {self.fault_thresholds[&#34;iaq&#34;][&#34;humidity_high&#34;]}%&#39;, timestamp)
            elif humidity &lt; self.fault_thresholds[&#39;iaq&#39;][&#39;humidity_low&#39;]:
                self.publish_alert(queue_name, device_id, did, &#39;humidity_low&#39;, f&#39;Humidity {humidity}% is below threshold {self.fault_thresholds[&#34;iaq&#34;][&#34;humidity_low&#34;]}%&#39;, timestamp)
        if co2 is not None:
            if co2 &gt; self.fault_thresholds[&#39;iaq&#39;][&#39;co2_high&#39;]:
                self.publish_alert(queue_name, device_id, did, &#39;co2_high&#39;, f&#39;CO2 level {co2} ppm exceeds threshold {self.fault_thresholds[&#34;iaq&#34;][&#34;co2_high&#34;]} ppm&#39;, timestamp)
        self.process_and_insert_data(sensor_data)

    elif sensor_type == &#39;power_meter&#39;:
        power_meter = sensor_data.get(&#39;power_meter&#39;)
        if power_meter is not None:
            # Simple power spike detection (can be enhanced with moving averages etc.)
            if power_meter &gt; self.fault_thresholds[&#39;power&#39;][&#39;power_spike_threshold&#39;]:
                self.publish_alert(queue_name, device_id, did, &#39;power_spike&#39;, f&#39;Power consumption spiked to {power_meter} kW on device {device_id}&#39;, timestamp)
        self.process_and_insert_data(sensor_data)

    elif sensor_type in [&#39;online_status&#39;, &#39;occupancy_status&#39;, &#39;sensitivity&#39;]:
        room_id = device_id.split(&#39;-&#39;)[2]
        occupancy_state = sensor_data.get(&#39;occupancy&#39;)
        if occupancy_state == &#39;occupied&#39;:
            self.last_occupied[room_id] = datetime.strptime(timestamp, &#39;%Y-%m-%dT%H:%M:%S.%f&#39;)
        elif occupancy_state == &#39;unoccupied&#39; and room_id in self.last_occupied:
            del self.last_occupied[room_id] # Reset if unoccupied

        # Detect if a room has been occupied for too long (potential sensor issue)
        if room_id in self.last_occupied:
            if (datetime.now() - self.last_occupied[room_id]).total_seconds() &gt; self.fault_thresholds[&#39;occupancy&#39;][&#39;stuck_occupied_timeout&#39;] * 3600:
                self.publish_alert(queue_name, device_id, did, &#39;stuck_occupied&#39;, f&#39;Room has been occupied since {self.last_occupied[room_id]}&#39;, timestamp)
        self.process_and_insert_data(sensor_data)</code></pre>
</details>
<div class="desc"><p>Detects faults in sensor data and publishes alerts if thresholds are exceeded.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>sensor_data</code></strong> :&ensp;<code>dict</code></dt>
<dd>A dictionary containing sensor data. Expected keys include:
- 'id' (str): The unique identifier for the data.
- 'device_id' (str): The unique identifier for the device.
- 'sensor_type' (str): The type of sensor (e.g., 'temperature', 'humidity', 'co2', 'power_meter', etc.).
- 'datetime' (str): The timestamp of the sensor data in ISO 8601 format.
- Additional keys depending on the sensor type (e.g., 'temperature', 'humidity', 'co2', 'power_meter', 'occupancy').</dd>
<dt><strong><code>queue_name</code></strong> :&ensp;<code>str</code></dt>
<dd>The name of the queue to which alerts should be published.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None</p>
<h2 id="behavior">Behavior</h2>
<ul>
<li>For 'temperature', 'humidity', and 'co2' sensors:<ul>
<li>Checks if the values exceed predefined thresholds for indoor air quality (IAQ).</li>
<li>Publishes alerts for high or low temperature, humidity, or high CO2 levels.</li>
<li>Processes and inserts the sensor data, marking whether an IAQ fault was detected.</li>
</ul>
</li>
<li>For 'power_meter' sensors:<ul>
<li>Detects power spikes based on a predefined threshold.</li>
<li>Publishes alerts for power spikes.</li>
<li>Processes and inserts the sensor data, marking whether a power fault was detected.</li>
</ul>
</li>
<li>For 'online_status', 'occupancy_status', and 'sensitivity' sensors:<ul>
<li>Tracks room occupancy states and timestamps.</li>
<li>Detects if a room has been marked as occupied for too long, indicating a potential sensor issue.</li>
<li>Publishes alerts for stuck occupancy states.</li>
<li>Processes and inserts the sensor data, marking whether an occupancy fault was detected.</li>
</ul>
</li>
<li>Logs warnings if incomplete sensor data is received.</li>
</ul></div>
</dd>
<dt id="agent.FaultDetectionAgent.get_default_thresholds"><code class="name flex">
<span>def <span class="ident">get_default_thresholds</span></span>(<span>self) ‚Äë>¬†dict</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_default_thresholds(self) -&gt; dict:
    &#34;&#34;&#34;Retrieve the default thresholds.&#34;&#34;&#34;
    return {
        &#39;iaq&#39;: {
            &#39;temperature_low&#39;: 18,
            &#39;temperature_high&#39;: 26,
            &#39;humidity_low&#39;: 30,
            &#39;humidity_high&#39;: 60,
            &#39;co2_low&#39;: 400,
            &#39;co2_high&#39;: 1000
        },
        &#39;power&#39;: {
            &#39;power_spike_threshold&#39;: 1
        },
        &#39;occupancy&#39;: {
            &#39;stuck_occupied_timeout&#39;: 24
        }
    }</code></pre>
</details>
<div class="desc"><p>Retrieve the default thresholds.</p></div>
</dd>
<dt id="agent.FaultDetectionAgent.get_initial_thresholds"><code class="name flex">
<span>def <span class="ident">get_initial_thresholds</span></span>(<span>self) ‚Äë>¬†dict</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_initial_thresholds(self) -&gt; dict:
    &#34;&#34;&#34;
    Retrieve initial fault detection thresholds from Supabase or use defaults.
    &#34;&#34;&#34;
    response = self.supabase.table(&#39;fault_thresholds&#39;).select(&#39;*&#39;).execute()
    if response.data:
        logging.info(&#34;üëæ Read thresholds from Supabase&#34;)
        return self.process_threshold_data(response.data[0])
    else:
        return self.get_default_thresholds()</code></pre>
</details>
<div class="desc"><p>Retrieve initial fault detection thresholds from Supabase or use defaults.</p></div>
</dd>
<dt id="agent.FaultDetectionAgent.get_queues_for_exchange"><code class="name flex">
<span>def <span class="ident">get_queues_for_exchange</span></span>(<span>self) ‚Äë>¬†list</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_queues_for_exchange(self) -&gt; list:
    &#34;&#34;&#34;
    Retrieve the list of queue names bound to a specific RabbitMQ exchange.
    &#34;&#34;&#34;
    rabbitmq_host = config(&#39;RABBITMQ_HOST&#39;)
    url = f&#39;http://{rabbitmq_host}:15672/api/bindings&#39;
    response = requests.get(url, auth=HTTPBasicAuth(&#39;guest&#39;, &#39;guest&#39;))
    
    if response.status_code == 200:
        bindings = response.json()
        queues = [
            binding[&#39;destination&#39;]
            for binding in bindings
            if binding[&#39;source&#39;] == config(&#39;EXCHANGE_NAME&#39;) and binding[&#39;destination_type&#39;] == &#39;queue&#39;
        ]
        return queues
    else:
        logging.error(f&#34;Failed to fetch bindings: {response.status_code}&#34;)
        return []</code></pre>
</details>
<div class="desc"><p>Retrieve the list of queue names bound to a specific RabbitMQ exchange.</p></div>
</dd>
<dt id="agent.FaultDetectionAgent.init_db_connection"><code class="name flex">
<span>def <span class="ident">init_db_connection</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def init_db_connection(self):
    self.conn = psycopg2.connect(
        dbname=self.DB_NAME,
        user=self.DB_USER,
        password=self.DB_PASSWORD,
        host=self.DB_HOST,
        port=self.DB_PORT
    )
    self.cursor = self.conn.cursor()

    # Check if table named raw_data exists
    self.cursor.execute(&#34;SELECT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_name = &#39;raw_data&#39;)&#34;)
    if self.cursor.fetchone()[0]:
        logging.info(&#34;üëæ TimescaleDB table &#39;raw_data&#39; exists.&#34;)
    else:
        logging.info(&#34;üëæ TimescaleDB table &#39;raw_data&#39; does not exist. Creating it...&#34;)
        self.cursor.execute(&#34;&#34;&#34;
            CREATE TABLE raw_data (
                id SERIAL PRIMARY KEY,
                timestamp BIGINT NOT NULL,
                datetime TIMESTAMP NOT NULL,
                device_id VARCHAR(50) NOT NULL,
                datapoint VARCHAR(50) NOT NULL,
                value TEXT NOT NULL,
                did INTEGER
            )
        &#34;&#34;&#34;)
        self.conn.commit()
        logging.info(&#34;üëæ TimescaleDB table &#39;raw_data&#39; created.&#34;)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="agent.FaultDetectionAgent.init_rabbitmq_connection"><code class="name flex">
<span>def <span class="ident">init_rabbitmq_connection</span></span>(<span>self) ‚Äë>¬†None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def init_rabbitmq_connection(self) -&gt; None:
    &#34;&#34;&#34;
    Initializes the RabbitMQ connection and sets up the exchange channel.
    &#34;&#34;&#34;
    # RabbitMQ connection
    self.connection = pika.BlockingConnection(pika.ConnectionParameters(self.RABBITMQ_HOST))
    self.channel = self.connection.channel()
    self.exchange = self.channel.exchange_declare(exchange=self.ALERT_EXCHANGE_NAME, exchange_type=&#39;topic&#39;)</code></pre>
</details>
<div class="desc"><p>Initializes the RabbitMQ connection and sets up the exchange channel.</p></div>
</dd>
<dt id="agent.FaultDetectionAgent.insert_row_data"><code class="name flex">
<span>def <span class="ident">insert_row_data</span></span>(<span>self, data) ‚Äë>¬†None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def insert_row_data(self, data) -&gt; None:
    &#34;&#34;&#34;
    Inserts processed row data into the raw_data database table.
    &#34;&#34;&#34;
    insert_queries = []
    skipped_keys = [&#39;datetime&#39;, &#39;device_id&#39;, &#39;id&#39;, &#39;sensor_type&#39;]
    timestamp = data[&#34;datetime&#34;]
    
    for key in data.keys():
        if key in skipped_keys:
            continue
        insert_queries.append((
            int(datetime.fromisoformat(timestamp).timestamp()),
            datetime.fromisoformat(timestamp),
            data[&#34;device_id&#34;],
            key,
            str(data[key]),
            data[&#34;id&#34;]
        ))

    self.cursor.executemany(
        &#34;&#34;&#34;
        INSERT INTO raw_data (timestamp, datetime, device_id, datapoint, value, did)
        VALUES (%s, %s, %s, %s, %s, %s)
        &#34;&#34;&#34;,
        insert_queries
    )
    self.conn.commit()</code></pre>
</details>
<div class="desc"><p>Inserts processed row data into the raw_data database table.</p></div>
</dd>
<dt id="agent.FaultDetectionAgent.process_and_insert_data"><code class="name flex">
<span>def <span class="ident">process_and_insert_data</span></span>(<span>self, data:¬†Dict[str,¬†Any]) ‚Äë>¬†None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def process_and_insert_data(self, data: Dict[str, Any]) -&gt; None:
    &#34;&#34;&#34;
    Processes incoming data and inserts it into the database if valid.
    &#34;&#34;&#34;
    if not data.get(&#34;datetime&#34;):
        logging.info(&#34; [!] No timestamp found in data.&#34;)
        return
    try:
        self.insert_row_data(data)
    except (TypeError, ValueError):
        logging.error(&#34; [!] Invalid IAQ sensor data received. Non-numeric values detected.&#34;)
        return
    except Exception as e:
        logging.error(f&#34; [!] Error inserting data into TimescaleDB: {e}&#34;)
        return</code></pre>
</details>
<div class="desc"><p>Processes incoming data and inserts it into the database if valid.</p></div>
</dd>
<dt id="agent.FaultDetectionAgent.process_threshold_data"><code class="name flex">
<span>def <span class="ident">process_threshold_data</span></span>(<span>self, record:¬†dict) ‚Äë>¬†dict</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def process_threshold_data(self, record: dict) -&gt; dict:
    &#34;&#34;&#34;
    Processes threshold data from a record dictionary into a structured format.
    &#34;&#34;&#34;
    return {
        &#39;iaq&#39;: {
            &#39;temperature_low&#39;: record.get(&#39;temperature_min&#39;),
            &#39;temperature_high&#39;: record.get(&#39;temperature_max&#39;),
            &#39;humidity_low&#39;: record.get(&#39;humidity_min&#39;),
            &#39;humidity_high&#39;: record.get(&#39;humidity_max&#39;),
            &#39;co2_low&#39;: record.get(&#39;co2_min&#39;),
            &#39;co2_high&#39;: record.get(&#39;co2_max&#39;)
        },
        &#39;power&#39;: {
            &#39;power_spike_threshold&#39;: record.get(&#39;power_kw_max&#39;)
        },
        &#39;occupancy&#39;: {
            &#39;stuck_occupied_timeout&#39;: record.get(&#39;sensitivity_max&#39;)
        }
    }</code></pre>
</details>
<div class="desc"><p>Processes threshold data from a record dictionary into a structured format.</p></div>
</dd>
<dt id="agent.FaultDetectionAgent.publish_alert"><code class="name flex">
<span>def <span class="ident">publish_alert</span></span>(<span>self, queue_name, device_id, did, fault_type, message, timestamp) ‚Äë>¬†None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def publish_alert(self,  queue_name, device_id, did, fault_type, message, timestamp) -&gt; None:
    &#34;&#34;&#34;
    Publishes an alert to RabbitMQ and Supabase.

    This method sends an alert message containing fault details to a specified
    RabbitMQ queue and also stores the alert data in Supabase for further processing
    or record-keeping.

    Args:
        queue_name (str): The name of the RabbitMQ queue to publish the alert to.
        device_id (str): The unique identifier of the device where the fault occurred.
        did (str): The unique identifier for the detection instance.
        fault_type (str): The type of fault detected (e.g., &#34;temperature_fault&#34;).
        message (str): A descriptive message providing details about the fault.
        timestamp (str): The timestamp when the fault was detected.

    Returns:
        None
    &#34;&#34;&#34;
    alert_data = {
        &#39;device_id&#39;: device_id,
        &#39;fault_type&#39;: fault_type,
        &#39;status&#39;: &#39;open&#39;,
        &#39;message&#39;: message,
        &#39;detected_at&#39;: timestamp,
        &#39;did&#39;: did,
    }
    self.publish_to_rabbitmq(queue_name, alert_data)
    self.publish_to_supabase(alert_data)</code></pre>
</details>
<div class="desc"><p>Publishes an alert to RabbitMQ and Supabase.</p>
<p>This method sends an alert message containing fault details to a specified
RabbitMQ queue and also stores the alert data in Supabase for further processing
or record-keeping.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>queue_name</code></strong> :&ensp;<code>str</code></dt>
<dd>The name of the RabbitMQ queue to publish the alert to.</dd>
<dt><strong><code>device_id</code></strong> :&ensp;<code>str</code></dt>
<dd>The unique identifier of the device where the fault occurred.</dd>
<dt><strong><code>did</code></strong> :&ensp;<code>str</code></dt>
<dd>The unique identifier for the detection instance.</dd>
<dt><strong><code>fault_type</code></strong> :&ensp;<code>str</code></dt>
<dd>The type of fault detected (e.g., "temperature_fault").</dd>
<dt><strong><code>message</code></strong> :&ensp;<code>str</code></dt>
<dd>A descriptive message providing details about the fault.</dd>
<dt><strong><code>timestamp</code></strong> :&ensp;<code>str</code></dt>
<dd>The timestamp when the fault was detected.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None</p></div>
</dd>
<dt id="agent.FaultDetectionAgent.publish_to_rabbitmq"><code class="name flex">
<span>def <span class="ident">publish_to_rabbitmq</span></span>(<span>self, queue_name, alert_data) ‚Äë>¬†None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def publish_to_rabbitmq(self, queue_name, alert_data) -&gt; None:
    &#34;&#34;&#34;
    Publishes alert data to a RabbitMQ queue.

    This method declares a queue with the specified queue name, binds it to the
    alert exchange using the routing key, and publishes the alert data to the queue.

    Args:
        queue_name (str): The name of the queue to publish the alert data to.
        alert_data (dict): The alert data to be published. It will be serialized to JSON format.

    Raises:
        pika.exceptions.AMQPError: If there is an error during queue declaration, binding, or publishing.
    &#34;&#34;&#34;
    routing_key = f&#39;_{queue_name}&#39;
    self.channel.queue_declare(queue=routing_key)
    self.channel.queue_bind(exchange=self.ALERT_EXCHANGE_NAME, queue=routing_key, routing_key=routing_key)
    self.channel.basic_publish(exchange=self.ALERT_EXCHANGE_NAME, routing_key=routing_key, body=json.dumps(alert_data))</code></pre>
</details>
<div class="desc"><p>Publishes alert data to a RabbitMQ queue.</p>
<p>This method declares a queue with the specified queue name, binds it to the
alert exchange using the routing key, and publishes the alert data to the queue.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>queue_name</code></strong> :&ensp;<code>str</code></dt>
<dd>The name of the queue to publish the alert data to.</dd>
<dt><strong><code>alert_data</code></strong> :&ensp;<code>dict</code></dt>
<dd>The alert data to be published. It will be serialized to JSON format.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>pika.exceptions.AMQPError</code></dt>
<dd>If there is an error during queue declaration, binding, or publishing.</dd>
</dl></div>
</dd>
<dt id="agent.FaultDetectionAgent.publish_to_supabase"><code class="name flex">
<span>def <span class="ident">publish_to_supabase</span></span>(<span>self, alert_data) ‚Äë>¬†None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def publish_to_supabase(self, alert_data) -&gt; None:
    &#34;&#34;&#34;
    Publishes alert data to the Supabase table.

    Args:
        alert_data (dict): A dictionary containing the alert data to be published.

    Returns:
        None
    &#34;&#34;&#34;
    try:
        response = self.supabase.table(&#39;fault_status&#39;).insert(alert_data).execute()
    except Exception as e:
        logging.error(f&#34; [!] Error publishing to Supabase: {e}&#34;)
        return</code></pre>
</details>
<div class="desc"><p>Publishes alert data to the Supabase table.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>alert_data</code></strong> :&ensp;<code>dict</code></dt>
<dd>A dictionary containing the alert data to be published.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None</p></div>
</dd>
<dt id="agent.FaultDetectionAgent.run_fault_detection"><code class="name flex">
<span>def <span class="ident">run_fault_detection</span></span>(<span>self) ‚Äë>¬†None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run_fault_detection(self) -&gt; None:
    &#34;&#34;&#34;
    Listens for sensor data messages and performs fault detection.
    &#34;&#34;&#34;
    channel = self.connection.channel()
    channel.exchange_declare(exchange=self.EXCHANGE_NAME, exchange_type=&#39;topic&#39;, durable=True)

    result = channel.queue_declare(queue=&#39;&#39;, durable=True, exclusive=True)
    queue_name = result.method.queue
    channel.queue_bind(exchange=self.EXCHANGE_NAME, queue=queue_name, routing_key=&#39;#&#39;)

    logging.info(&#34;üëæüêá Waiting for sensor data...&#34;)

    def callback(ch, method, properties, body):
        try:
            data = json.loads(body.decode())
            self.detect_faults(data, method.routing_key)
        except Exception as e:
            logging.error(&#34;[!] Error processing message:&#34;, e)
    channel.basic_consume(queue=queue_name, on_message_callback=callback, auto_ack=True)
    channel.start_consuming()</code></pre>
</details>
<div class="desc"><p>Listens for sensor data messages and performs fault detection.</p></div>
</dd>
<dt id="agent.FaultDetectionAgent.setup_realtime_subscription"><code class="name flex">
<span>async def <span class="ident">setup_realtime_subscription</span></span>(<span>self) ‚Äë>¬†None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def setup_realtime_subscription(self) -&gt; None:
    &#34;&#34;&#34;
    Sets up a realtime subscription to monitor and handle table changes.
    &#34;&#34;&#34;
    async_client = await create_async_client(config(&#39;SUPABASE_URL&#39;), config(&#39;SUPABASE_API_KEY&#39;))

    def handle_change(payload):
        logging.info(&#34;üëæ Threshold updated from somewhere else!&#34;)
        if payload[&#39;event_type&#39;] in (&#39;INSERT&#39;, &#39;UPDATE&#39;):
            self.fault_thresholds = self.process_threshold_data(payload[&#39;new&#39;])
        elif payload[&#39;event_type&#39;] == &#39;DELETE&#39;:
            self.fault_thresholds = self.get_default_thresholds()

    channel = await async_client.channel(&#39;threshold_changes&#39;)\
        .on_postgres_changes(
            event=&#39;UPDATE&#39;,
            schema=&#39;public&#39;,
            table=&#39;fault_thresholds&#39;,
            callback=handle_change
        ).subscribe()
    logging.info(f&#34;üëæ[‚úì] Realtime subscription active for threshold values. {async_client.realtime.is_connected}&#34;)
    while True:
        await asyncio.sleep(3600)</code></pre>
</details>
<div class="desc"><p>Sets up a realtime subscription to monitor and handle table changes.</p></div>
</dd>
</dl>
</dd>
<dt id="agent.IAQSensorSimulator"><code class="flex name class">
<span>class <span class="ident">IAQSensorSimulator</span></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class IAQSensorSimulator:
    &#34;&#34;&#34;
    Attributes:
        RABBITMQ_URL (str): The RabbitMQ connection URL.
        RABBITMQ_HOST (str): The RabbitMQ host address.
        EXCHANGE_NAME (str): The name of the RabbitMQ exchange.
        interval_seconds (int): The interval in seconds between data generation cycles.
        interval_total_seconds (int): The total elapsed time in seconds for the simulation.
        connection (aio_pika.Connection): The RabbitMQ connection object.
        channel (aio_pika.Channel): The RabbitMQ channel object.
        exchange (aio_pika.Exchange): The RabbitMQ exchange object.
        supabase (supabase.Client): The Supabase client for interacting with the database.
    Methods:
        __init__():
            Initializes the IAQSensorSimulator with RabbitMQ and Supabase configurations.
        init_rabbitmq():
            Asynchronously initializes the RabbitMQ connection, channel, and exchange.
        close_rabbitmq():
            Asynchronously closes the RabbitMQ connection and channel.
        get_devices_from_supabase():
            Fetches the list of devices from the Supabase database.
        generate_iaq_data(device_id):
            Generates basic IAQ data (temperature, humidity, CO2) for a given device.
        generate_iaq_data_advanced(device_id, did, sensor_type, ...):
            Generates advanced IAQ data with sinusoidal patterns, noise, and spikes.
        generate_occupancy_data_advanced(device_id, did, sensor_type):
            Generates advanced occupancy data, including online status, sensitivity, and occupancy status.
        generate_power_data_advanced(device_id, did, sensor_type):
            Generates advanced power consumption data with base levels, noise, and spikes.
        generate_iot_data(device_id, did, sensor_type):
            Generates IoT data for a specific sensor type (e.g., temperature, humidity, power meter).
        publish_to_rabbitmq(data_list):
            Publishes a list of sensor data to RabbitMQ with appropriate routing keys.
        publish_batch(json_list):
            Asynchronously publishes a batch of sensor data to RabbitMQ.
        publish_to_supabase(data_list):
            Publishes a list of sensor data to the Supabase database.
        run_simulation():
            Runs the IAQ sensor simulation, generating and publishing data at regular intervals.
    &#34;&#34;&#34;
    def __init__(self):
        &#34;&#34;&#34;
        Initializes the simulation agent with RabbitMQ and Supabase configurations.
        &#34;&#34;&#34;
        # RabbitMQ connection parameters
        self.RABBITMQ_URL = f&#34;amqp://{config(&#39;RABBITMQ_USER&#39;)}:{config(&#39;RABBITMQ_PASSWORD&#39;)}@{config(&#39;RABBITMQ_HOST&#39;)}:{config(&#39;RABBITMQ_PORT&#39;)}/&#34;
        self.RABBITMQ_HOST = config(&#39;RABBITMQ_HOST&#39;)
        self.EXCHANGE_NAME = config(&#39;EXCHANGE_NAME&#39;, default=&#39;hotel_iot&#39;)
        self.interval_seconds = 5
        self.interval_total_seconds = self.interval_seconds
        self.current_time = datetime.now()

        # RabbitMQ setup
        self.connection = None
        self.channel = None
        self.exchange = None

        # Supabase setup
        # Initialize Supabase client
        SUPABASE_URL = config(&#39;SUPABASE_URL&#39;)
        SUPABASE_API_KEY = config(&#39;SUPABASE_API_KEY&#39;)
        self.supabase = create_client(SUPABASE_URL, SUPABASE_API_KEY)

    async def init_rabbitmq(self) -&gt; None:
        &#34;&#34;&#34;
        Initialize a connection to RabbitMQ using a robust connection and set up
        a communication channel with a durable topic exchange.

        This method establishes a robust connection to the RabbitMQ server using
        the provided RabbitMQ URL, creates a communication channel, and declares
        a durable topic exchange with the specified exchange name.
        &#34;&#34;&#34;
        self.connection = await connect_robust(self.RABBITMQ_URL)
        self.channel = await self.connection.channel()
        self.exchange = await self.channel.declare_exchange(
                            name=self.EXCHANGE_NAME,
                            type=&#39;topic&#39;,
                            durable=True
                        )

    async def close_rabbitmq(self) -&gt; None:
        &#34;&#34;&#34;
        Asynchronously closes the RabbitMQ channel and connection.

        This method ensures that both the channel and connection to RabbitMQ
        are properly closed if they exist. It first closes the channel, followed
        by the connection, to release resources and clean up.

        Raises:
            Any exceptions raised during the closing of the channel or connection.
        &#34;&#34;&#34;
        if self.channel:
            await self.channel.close()
        if self.connection:
            await self.connection.close()

    def get_devices_from_supabase(self) -&gt; list:
        &#34;&#34;&#34;
        Fetches a list of devices from the Supabase database.

        This method queries the &#39;devices&#39; table in the Supabase database and retrieves
        all records. If devices are found, they are returned as a list. If no devices
        are found, an empty list is returned, and a message is printed to indicate this.

        Returns:
            list: A list of device records if found, otherwise an empty list.
        &#34;&#34;&#34;
        # Fetch devices from Supabase
        devices = self.supabase.table(&#39;devices&#39;).select(&#39;*&#39;).execute()
        if devices.data:
            return devices.data
        else:
            logging.info(&#34;No devices found in Supabase.&#34;)
            return []

    def generate_iaq_data_advanced(self,
                                   temperature_base=27,
                                   temperature_amplitude=0.5,
                                   humidity_base=50,
                                   humidity_amplitude=0.5,
                                   co2_base=500,
                                   co2_spike_chance=0.01,
                                   co2_spike_magnitude_range=(300, 800),
                                   temperature_noise_std=0.05,
                                   humidity_noise_std=1.5,
                                   co2_noise_std=20) -&gt; tuple:
        &#34;&#34;&#34;
        Generate advanced Indoor Air Quality (IAQ) data including temperature, humidity, and CO2 levels.
        This method simulates IAQ data using sinusoidal patterns, diurnal adjustments, random noise, 
        and occasional CO2 spikes to mimic real-world environmental variations.
        Args:
            device_id (str): The unique identifier for the device generating the data.
            did (str): Device ID or additional identifier for the data source.
            sensor_type (str): The type of sensor generating the data.
            start_time_str (str, optional): The starting timestamp for the simulation in the format 
                &#34;YYYY-MM-DD HH:MM:SS&#34;. Defaults to &#34;2024-12-27 00:00:00&#34;.
            temperature_base (float, optional): The base temperature value in degrees Celsius. Defaults to 27.
            temperature_amplitude (float, optional): The amplitude of the sinusoidal temperature variation. Defaults to 0.5.
            humidity_base (float, optional): The base humidity value in percentage. Defaults to 50.
            humidity_amplitude (float, optional): The amplitude of the sinusoidal humidity variation. Defaults to 0.5.
            co2_base (int, optional): The base CO2 level in ppm. Defaults to 500.
            co2_spike_chance (float, optional): The probability of a CO2 spike occurring at each time step. Defaults to 0.01.
            co2_spike_magnitude_range (tuple, optional): The range of CO2 spike magnitudes in ppm. Defaults to (300, 800).
            temperature_noise_std (float, optional): The standard deviation of random noise added to temperature. Defaults to 0.05.
            humidity_noise_std (float, optional): The standard deviation of random noise added to humidity. Defaults to 1.5.
            co2_noise_std (float, optional): The standard deviation of random noise added to CO2 levels. Defaults to 20.
        Returns:
            tuple: A tuple containing:
                - temperature (float): The simulated temperature value in degrees Celsius.
                - humidity (float): The simulated humidity value in percentage.
                - co2 (float): The simulated CO2 level in ppm.
        &#34;&#34;&#34;
        current_time = self.current_time + self.interval_total_seconds * timedelta(seconds=1)
        t_sec = current_time.second
        co2_spike_value = 0
        co2_spike_decay = 0

        # Temperature: base + sinusoidal pattern with a 24-hour cycle + noise
        temperature = temperature_base + temperature_amplitude * math.sin(2 * math.pi * t_sec / 86400 - math.pi / 2)
        hour_of_day = current_time.hour + current_time.minute / 60
        diurnal_adjustment = -5 * math.cos(2 * math.pi * hour_of_day / 24)
        temperature += diurnal_adjustment
        temperature += random.gauss(0, temperature_noise_std)

        # Humidity inverse of temperature with sinusoidal pattern + noise
        humidity = humidity_base - humidity_amplitude * math.sin(2 * math.pi * t_sec / 86400 - math.pi / 2)
        humidity += random.gauss(0, humidity_noise_std)
        humidity = max(30, min(70, humidity))

        # CO2 base level and spikes
        co2_base = max(400, min(1200, co2_base))
        if co2_spike_value &gt; 0:
            co2_spike_value *= co2_spike_decay
        elif random.random() &lt; co2_spike_chance:
            co2_spike_value = random.randint(*co2_spike_magnitude_range)
            co2_spike_decay = random.uniform(0.95, 0.99)
        co2 = co2_base + co2_spike_value + random.gauss(0, co2_noise_std)

        return temperature, humidity, co2

    def generate_occupancy_data_advanced(self) -&gt; tuple:
        &#34;&#34;&#34;
        Generates advanced occupancy data for a given device.
        This method simulates the occupancy status, online status, and sensitivity 
        of a device based on the current time and random chance. It also introduces 
        a small probability of anomalies in the generated data.
        Args:
            device_id (str): The unique identifier of the device.
            did (str): The device ID used for internal processing.
            sensor_type (str): The type of sensor associated with the device.
        Returns:
            tuple: A tuple containing:
                - online_status (str): The online status of the device, either &#39;online&#39; or &#39;offline&#39;.
                - sensitivity (str): The sensitivity level of the device, represented as a percentage 
                    (&#39;0%&#39;, &#39;25%&#39;, &#39;50%&#39;, &#39;75%&#39;, or &#39;100%&#39;).
                - occupancy_status (str): The occupancy status of the device, either &#39;occupied&#39; or &#39;unoccupied&#39;.
        &#34;&#34;&#34;
        current_time = self.current_time + self.interval_total_seconds * timedelta(seconds=1)
        if 0 &lt;= current_time.hour &lt; 6 or 12 &lt;= current_time.hour &lt; 18:
            occupancy_status = &#39;unoccupied&#39;
            occupancy_chance = random.random()
            if occupancy_chance &lt; 0.02:
                occupancy_status = &#39;occupied&#39;
        else:
            occupancy_status = &#39;occupied&#39;

        online_chance = random.random()
        if online_chance &lt; 0.02:
            online_status = &#39;offline&#39;
        else:
            online_status = &#39;online&#39;

        if online_status == &#39;offline&#39;:
            sensitivity = &#39;0%&#39;
        elif random.random() &gt; 0.02:
            sensitivity = &#39;100%&#39;
        else:
            sensitivity = random.choice([&#39;0%&#39;, &#39;25%&#39;, &#39;50%&#39;, &#39;75%&#39;])
        
        return online_status, sensitivity, occupancy_status

    def generate_power_data_advanced(self) -&gt; float:
        &#34;&#34;&#34;
        Generates simulated power consumption data for a device with advanced features 
        such as random noise, base power, and occasional power spikes.
        Args:
            device_id (str): The unique identifier for the device.
            did (str): Additional identifier for the device (not used in the current implementation).
            sensor_type (str): The type of sensor associated with the device (not used in the current implementation).
        Returns:
            float: Simulated power consumption value in kilowatts (kW).
        Notes:
            - The base power consumption is randomly generated within a range of 0.1 to 2.5 kW.
            - Power spikes occur with a 10% probability and have a magnitude between 3 and 10 kW.
            - Power spikes decay over time with a random decay factor between 0.95 and 0.99.
            - Random Gaussian noise with a standard deviation of 0.1 kW is added to the final power value.
        &#34;&#34;&#34;
        power_spike_magnitude_range = (3, 10)  # kW
        power_base = random.uniform(0.1, 2.5)  # kW
        power_noise_std = 0.1  # kW
        power_spike_chance = random.random()
        power_spike_decay = random.uniform(0.95, 0.99)
        power_spike_value = 0

        if power_spike_value &gt; 0:
            power_spike_value *= power_spike_decay
        elif power_spike_chance &lt; 0.1:  # 10% chance of a spike
            power_spike_value = random.randint(*power_spike_magnitude_range)
            power_spike_decay = random.uniform(0.95, 0.99)

        power_meter = power_base + power_spike_value + random.gauss(0, power_noise_std)
        return power_meter

    def generate_iot_data(self, device_id, did, sensor_type) -&gt; dict:
        &#34;&#34;&#34;
        Generates IoT data for a given device based on the specified sensor type.
        Args:
            device_id (str): The unique identifier of the IoT device.
            did (str): The unique identifier for the data entry.
            sensor_type (str): The type of sensor data to generate. 
                Supported values are:
                - &#39;power_meter&#39;: Generates power meter data.
                - &#39;temperature&#39;: Generates temperature data.
                - &#39;humidity&#39;: Generates humidity data.
                - &#39;co2&#39;: Generates CO2 data.
                - &#39;online_status&#39;: Generates online status data.
                - &#39;occupancy_status&#39;: Generates occupancy status data.
                - &#39;sensitivity&#39;: Generates sensitivity data.
        Returns:
            dict: A dictionary containing the generated IoT data with the following keys:
                - &#34;datetime&#34; (str): The ISO 8601 formatted timestamp of the data.
                - &#34;id&#34; (str): The unique identifier for the data entry.
                - &#34;device_id&#34; (str): The unique identifier of the IoT device.
                - &#34;&lt;sensor_type&gt;&#34; (varies): The generated value for the specified sensor type.
                - &#34;sensor_type&#34; (str): The type of sensor data generated.
        Notes:
            - The method uses helper functions to generate specific types of data:
              `generate_iaq_data_advanced`, `generate_occupancy_data_advanced`, and 
              `generate_power_data_advanced`.
            - The `locals()` function is used to dynamically access the generated 
              sensor data based on the `sensor_type`.
        &#34;&#34;&#34;
        # NOTE: These variables are used in locals() to access the generated data
        temperature, humidity, co2 = self.generate_iaq_data_advanced()
        online_status, sensitivity, occupancy_status = self.generate_occupancy_data_advanced()
        power_meter = self.generate_power_data_advanced()
        if sensor_type == &#39;power_meter&#39;:
            return {
                &#34;datetime&#34;: self.current_time.isoformat(),
                &#39;id&#39;: did,
                &#34;device_id&#34;: device_id,
                &#34;power_meter&#34;: round(power_meter, 2),
                &#34;sensor_type&#34;: sensor_type
            }
        elif sensor_type in [&#39;temperature&#39;, &#39;humidity&#39;, &#39;co2&#39;]:
            return {
                &#34;datetime&#34;: self.current_time.isoformat(),
                &#34;id&#34;: did,
                &#34;device_id&#34;: device_id,
                sensor_type: round(locals()[sensor_type], 2),
                &#34;sensor_type&#34;: sensor_type
            }
        elif sensor_type in [&#39;online_status&#39;, &#39;occupancy_status&#39;, &#39;sensitivity&#39;]:
            return {
                &#34;datetime&#34;: self.current_time.isoformat(),
                &#34;id&#34;: did,
                &#34;device_id&#34;: device_id,
                sensor_type: locals()[sensor_type],
                &#34;sensor_type&#34;: sensor_type
            }

    def publish_to_rabbitmq(self, data_list) -&gt; None:
        &#34;&#34;&#34;
        Publishes a list of data to RabbitMQ with dynamically generated routing keys.
        This method processes a list of data dictionaries, determines the appropriate
        routing key for each data item based on its `sensor_type` and `device_id`, and
        publishes the data to a RabbitMQ exchange.
        Args:
            data_list (list): A list of dictionaries, where each dictionary represents
                a data item to be published. Each dictionary must contain the following keys:
                - &#39;device_id&#39; (str): The unique identifier of the device, formatted as a
                  string with parts separated by hyphens.
                - &#39;sensor_type&#39; (str): The type of sensor (e.g., &#39;temperature&#39;, &#39;humidity&#39;,
                  &#39;power_meter_...&#39;, etc.).
        Routing Key Generation:
            - For sensor types starting with &#39;power_meter_&#39;, the routing key suffix is &#34;POW&#34;.
            - For other sensor types, the suffix is determined by the `routing_key_map`.
            - If the sensor type is not found in the `routing_key_map`, the suffix defaults
              to &#34;UNKNOWN&#34;.
            - The final routing key is constructed by combining the first three parts of
              the `device_id` with the suffix, separated by hyphens.
        RabbitMQ Operations:
            - Declares a queue with the generated routing key.
            - Binds the queue to the specified exchange using the routing key.
            - Publishes the data to the exchange with the routing key.
        Raises:
            KeyError: If a required key (&#39;device_id&#39; or &#39;sensor_type&#39;) is missing from a
                data dictionary in the `data_list`.
            Exception: If there is an issue with RabbitMQ operations (e.g., queue declaration,
                binding, or publishing).
        Note:
            This method assumes that `self.channel` is a valid RabbitMQ channel and
            `self.EXCHANGE_NAME` is the name of the RabbitMQ exchange to publish to.
        &#34;&#34;&#34;
        routing_key_map = {
            &#39;temperature&#39;: &#39;IAQ&#39;,
            &#39;humidity&#39;: &#39;IAQ&#39;,
            &#39;co2&#39;: &#39;IAQ&#39;,
            &#39;online_status&#39;: &#39;OCC&#39;,
            &#39;occupancy_status&#39;: &#39;OCC&#39;,
            &#39;sensitivity&#39;: &#39;OCC&#39;
        }

        for data in data_list:
            device_id_parts = data[&#39;device_id&#39;].split(&#39;-&#39;)
            sensor_type = data[&#39;sensor_type&#39;]
            if sensor_type.startswith(&#39;power_meter_&#39;):
                routing_key_suffix = &#34;POW&#34;
            else:
                routing_key_suffix = routing_key_map.get(sensor_type, &#34;UNKNOWN&#34;)
            routing_key = &#39;-&#39;.join(device_id_parts[:3]) + f&#34;-{routing_key_suffix}&#34;
            self.channel.queue_declare(queue=routing_key)
            self.channel.queue_bind(exchange=self.EXCHANGE_NAME, queue=routing_key, routing_key=routing_key)
            self.channel.basic_publish(exchange=self.EXCHANGE_NAME, routing_key=routing_key, body=json.dumps(data))

    async def publish_batch(self, json_list) -&gt; None:
        &#34;&#34;&#34;
        Publishes a batch of JSON messages to RabbitMQ queues based on sensor types.
        This asynchronous method connects to a RabbitMQ server, declares queues dynamically
        based on the `sensor_type` field in each message, binds the queues to an exchange,
        and publishes the messages to the appropriate queues.
        Args:
            json_list (list): A list of dictionaries, where each dictionary represents a 
                              JSON message containing a `sensor_type` key and other data.
        Raises:
            Exception: If there is an issue with connecting to RabbitMQ, declaring queues,
                       or publishing messages.
        Notes:
            - The RabbitMQ connection URL is retrieved from the `RABBITMQ_URL` environment variable.
            - The queues are declared as durable, ensuring they persist even if RabbitMQ restarts.
            - The messages are published with a delivery mode of 2, making them persistent.
            - The method uses asyncio to handle multiple tasks concurrently.
        &#34;&#34;&#34;
        connection = await connect_robust(self.RABBITMQ_URL)
        channel = await connection.channel()
        tasks = []
        for msg in json_list:
            sensor_type = msg[&#39;sensor_type&#39;]
            queue_name = f&#34;{sensor_type}_queue&#34;
            await channel.declare_queue(queue_name, durable=True)
            queue = await channel.declare_queue(queue_name, durable=True)
            await queue.bind(self.EXCHANGE_NAME, routing_key=queue_name)
            tasks.append(
                self.exchange.publish(
                    Message(body=json.dumps(msg).encode(), delivery_mode=2),
                    routing_key=queue_name
                )
            )

        await asyncio.gather(*tasks)
        await connection.close()

    def publish_to_supabase(self, data_list) -&gt; None:
        &#34;&#34;&#34;
        Publishes a list of sensor data to a Supabase table.

        This method transforms the input data into the required format and uploads it
        to the &#39;sensor_data_latest&#39; table in Supabase. The transformation includes
        mapping the input data to a dictionary with specific keys and converting the
        timestamp to a Unix timestamp.

        Args:
            data_list (list): A list of dictionaries, where each dictionary contains
                the following keys:
                - &#39;device_id&#39; (str): The unique identifier of the device.
                - &#39;sensor_type&#39; (str): The type of sensor (e.g., temperature, humidity).
                - &#39;datetime&#39; (str): The ISO 8601 formatted datetime string.
                - &#39;id&#39; (int): The unique identifier for the data point.
                - A key matching the value of &#39;sensor_type&#39; (e.g., &#39;temperature&#39;): The
                  sensor reading value.

        Raises:
            ValueError: If the &#39;datetime&#39; field in the input data cannot be parsed
                into a valid datetime object.

        Notes:
            - The &#39;timestamp&#39; field is derived from the &#39;datetime&#39; field and is stored
              as a Unix timestamp.
            - The &#39;did&#39; field is derived from the &#39;id&#39; field and is stored as an integer.
            - The &#39;upsert&#39; operation ensures that existing records with the same
              &#39;device_id&#39; and &#39;datapoint&#39; are updated, while new records are inserted.
        &#34;&#34;&#34;
        # transform data_list to a list of dictionaries with the required keys to match the Supabase table
        data_list = list(map(lambda x: {
            &#39;device_id&#39;: x[&#39;device_id&#39;],
            &#39;datapoint&#39;: x[&#39;sensor_type&#39;],
            &#39;value&#39;: x[x[&#39;sensor_type&#39;]],
            &#39;timestamp&#39;: int(datetime.fromisoformat(x[&#39;datetime&#39;]).timestamp()),
            &#39;datetime&#39;: x[&#39;datetime&#39;],
            &#39;did&#39;: int(x[&#39;id&#39;])}, data_list))
        self.supabase.table(&#39;sensor_data_latest&#39;).upsert(data_list, on_conflict=&#39;device_id, datapoint&#39;).execute()

    async def run_simulation(self) -&gt; None:
        &#34;&#34;&#34;
        Runs the IAQ (Indoor Air Quality) Sensor Simulator.
        This asynchronous method initializes RabbitMQ, retrieves devices from Supabase, 
        generates IoT data for each device, and publishes the data to both Supabase 
        and RabbitMQ in batches. The simulation runs for a specified number of entries 
        or until interrupted.
        &#34;&#34;&#34;
        logging.basicConfig(level=logging.INFO, format=&#39;%(asctime)s - %(levelname)s - %(message)s&#39;)
        # Silence Supabase Realtime logs
        logging.getLogger(&#34;pika&#34;).setLevel(logging.WARNING)
        logging.getLogger(&#39;realtime&#39;).setLevel(logging.WARNING)
        logging.getLogger(&#39;realtime._async.client&#39;).setLevel(logging.WARNING)
        logging.getLogger(&#39;realtime._async.channel&#39;).setLevel(logging.WARNING)
        # Optionally, silence other related loggers
        logging.getLogger(&#39;httpx&#39;).setLevel(logging.WARNING)
        logging.getLogger(&#39;asyncio&#39;).setLevel(logging.WARNING)
        logging.getLogger(&#39;phx_websocket&#39;).setLevel(logging.WARNING)
        logging.getLogger(&#39;phoenix&#39;).setLevel(logging.WARNING)
        logging.getLogger(&#39;websockets&#39;).setLevel(logging.WARNING)

        logging.info(&#34;ü§ñ IAQ Sensor Simulator started.&#34;)
        logging.info(&#34;ü§ñ RabbitMQ dashboard available at: http://localhost:15672&#34;)
        get_devices = self.get_devices_from_supabase()
        await self.init_rabbitmq()

        try:
            max_entries = config(&#39;MAX_ENTRIES&#39;, default=1000, cast=int)
            for _ in range(max_entries):
                iaq_data_list = list(map(
                    lambda d: self.generate_iot_data(d[&#39;device_identifier&#39;], d[&#39;id&#39;], d[&#39;sensor_type&#39;]),
                    get_devices
                ))
                iaq_data_list = list(filter(None, iaq_data_list))
                self.publish_to_supabase(iaq_data_list)
                await self.publish_batch(iaq_data_list)
                self.current_time = datetime.now()
                await asyncio.sleep(self.interval_seconds)

        except KeyboardInterrupt:
            logging.info(&#34;IAQ Sensor Simulator stopped.&#34;)
        except Exception as e:
            logging.error(f&#34;Simulation error: {e}&#34;)
        finally:
            await self.close_rabbitmq()
            logging.info(&#34;Cleanup done. Bye!&#34;)</code></pre>
</details>
<div class="desc"><h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>RABBITMQ_URL</code></strong> :&ensp;<code>str</code></dt>
<dd>The RabbitMQ connection URL.</dd>
<dt><strong><code>RABBITMQ_HOST</code></strong> :&ensp;<code>str</code></dt>
<dd>The RabbitMQ host address.</dd>
<dt><strong><code>EXCHANGE_NAME</code></strong> :&ensp;<code>str</code></dt>
<dd>The name of the RabbitMQ exchange.</dd>
<dt><strong><code>interval_seconds</code></strong> :&ensp;<code>int</code></dt>
<dd>The interval in seconds between data generation cycles.</dd>
<dt><strong><code>interval_total_seconds</code></strong> :&ensp;<code>int</code></dt>
<dd>The total elapsed time in seconds for the simulation.</dd>
<dt><strong><code>connection</code></strong> :&ensp;<code>aio_pika.Connection</code></dt>
<dd>The RabbitMQ connection object.</dd>
<dt><strong><code>channel</code></strong> :&ensp;<code>aio_pika.Channel</code></dt>
<dd>The RabbitMQ channel object.</dd>
<dt><strong><code>exchange</code></strong> :&ensp;<code>aio_pika.Exchange</code></dt>
<dd>The RabbitMQ exchange object.</dd>
<dt><strong><code>supabase</code></strong> :&ensp;<code>supabase.Client</code></dt>
<dd>The Supabase client for interacting with the database.</dd>
</dl>
<h2 id="methods">Methods</h2>
<p><strong>init</strong>():
Initializes the IAQSensorSimulator with RabbitMQ and Supabase configurations.
init_rabbitmq():
Asynchronously initializes the RabbitMQ connection, channel, and exchange.
close_rabbitmq():
Asynchronously closes the RabbitMQ connection and channel.
get_devices_from_supabase():
Fetches the list of devices from the Supabase database.
generate_iaq_data(device_id):
Generates basic IAQ data (temperature, humidity, CO2) for a given device.
generate_iaq_data_advanced(device_id, did, sensor_type, &hellip;):
Generates advanced IAQ data with sinusoidal patterns, noise, and spikes.
generate_occupancy_data_advanced(device_id, did, sensor_type):
Generates advanced occupancy data, including online status, sensitivity, and occupancy status.
generate_power_data_advanced(device_id, did, sensor_type):
Generates advanced power consumption data with base levels, noise, and spikes.
generate_iot_data(device_id, did, sensor_type):
Generates IoT data for a specific sensor type (e.g., temperature, humidity, power meter).
publish_to_rabbitmq(data_list):
Publishes a list of sensor data to RabbitMQ with appropriate routing keys.
publish_batch(json_list):
Asynchronously publishes a batch of sensor data to RabbitMQ.
publish_to_supabase(data_list):
Publishes a list of sensor data to the Supabase database.
run_simulation():
Runs the IAQ sensor simulation, generating and publishing data at regular intervals.</p>
<p>Initializes the simulation agent with RabbitMQ and Supabase configurations.</p></div>
<h3>Methods</h3>
<dl>
<dt id="agent.IAQSensorSimulator.close_rabbitmq"><code class="name flex">
<span>async def <span class="ident">close_rabbitmq</span></span>(<span>self) ‚Äë>¬†None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def close_rabbitmq(self) -&gt; None:
    &#34;&#34;&#34;
    Asynchronously closes the RabbitMQ channel and connection.

    This method ensures that both the channel and connection to RabbitMQ
    are properly closed if they exist. It first closes the channel, followed
    by the connection, to release resources and clean up.

    Raises:
        Any exceptions raised during the closing of the channel or connection.
    &#34;&#34;&#34;
    if self.channel:
        await self.channel.close()
    if self.connection:
        await self.connection.close()</code></pre>
</details>
<div class="desc"><p>Asynchronously closes the RabbitMQ channel and connection.</p>
<p>This method ensures that both the channel and connection to RabbitMQ
are properly closed if they exist. It first closes the channel, followed
by the connection, to release resources and clean up.</p>
<h2 id="raises">Raises</h2>
<p>Any exceptions raised during the closing of the channel or connection.</p></div>
</dd>
<dt id="agent.IAQSensorSimulator.generate_iaq_data_advanced"><code class="name flex">
<span>def <span class="ident">generate_iaq_data_advanced</span></span>(<span>self,<br>temperature_base=27,<br>temperature_amplitude=0.5,<br>humidity_base=50,<br>humidity_amplitude=0.5,<br>co2_base=500,<br>co2_spike_chance=0.01,<br>co2_spike_magnitude_range=(300, 800),<br>temperature_noise_std=0.05,<br>humidity_noise_std=1.5,<br>co2_noise_std=20) ‚Äë>¬†tuple</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_iaq_data_advanced(self,
                               temperature_base=27,
                               temperature_amplitude=0.5,
                               humidity_base=50,
                               humidity_amplitude=0.5,
                               co2_base=500,
                               co2_spike_chance=0.01,
                               co2_spike_magnitude_range=(300, 800),
                               temperature_noise_std=0.05,
                               humidity_noise_std=1.5,
                               co2_noise_std=20) -&gt; tuple:
    &#34;&#34;&#34;
    Generate advanced Indoor Air Quality (IAQ) data including temperature, humidity, and CO2 levels.
    This method simulates IAQ data using sinusoidal patterns, diurnal adjustments, random noise, 
    and occasional CO2 spikes to mimic real-world environmental variations.
    Args:
        device_id (str): The unique identifier for the device generating the data.
        did (str): Device ID or additional identifier for the data source.
        sensor_type (str): The type of sensor generating the data.
        start_time_str (str, optional): The starting timestamp for the simulation in the format 
            &#34;YYYY-MM-DD HH:MM:SS&#34;. Defaults to &#34;2024-12-27 00:00:00&#34;.
        temperature_base (float, optional): The base temperature value in degrees Celsius. Defaults to 27.
        temperature_amplitude (float, optional): The amplitude of the sinusoidal temperature variation. Defaults to 0.5.
        humidity_base (float, optional): The base humidity value in percentage. Defaults to 50.
        humidity_amplitude (float, optional): The amplitude of the sinusoidal humidity variation. Defaults to 0.5.
        co2_base (int, optional): The base CO2 level in ppm. Defaults to 500.
        co2_spike_chance (float, optional): The probability of a CO2 spike occurring at each time step. Defaults to 0.01.
        co2_spike_magnitude_range (tuple, optional): The range of CO2 spike magnitudes in ppm. Defaults to (300, 800).
        temperature_noise_std (float, optional): The standard deviation of random noise added to temperature. Defaults to 0.05.
        humidity_noise_std (float, optional): The standard deviation of random noise added to humidity. Defaults to 1.5.
        co2_noise_std (float, optional): The standard deviation of random noise added to CO2 levels. Defaults to 20.
    Returns:
        tuple: A tuple containing:
            - temperature (float): The simulated temperature value in degrees Celsius.
            - humidity (float): The simulated humidity value in percentage.
            - co2 (float): The simulated CO2 level in ppm.
    &#34;&#34;&#34;
    current_time = self.current_time + self.interval_total_seconds * timedelta(seconds=1)
    t_sec = current_time.second
    co2_spike_value = 0
    co2_spike_decay = 0

    # Temperature: base + sinusoidal pattern with a 24-hour cycle + noise
    temperature = temperature_base + temperature_amplitude * math.sin(2 * math.pi * t_sec / 86400 - math.pi / 2)
    hour_of_day = current_time.hour + current_time.minute / 60
    diurnal_adjustment = -5 * math.cos(2 * math.pi * hour_of_day / 24)
    temperature += diurnal_adjustment
    temperature += random.gauss(0, temperature_noise_std)

    # Humidity inverse of temperature with sinusoidal pattern + noise
    humidity = humidity_base - humidity_amplitude * math.sin(2 * math.pi * t_sec / 86400 - math.pi / 2)
    humidity += random.gauss(0, humidity_noise_std)
    humidity = max(30, min(70, humidity))

    # CO2 base level and spikes
    co2_base = max(400, min(1200, co2_base))
    if co2_spike_value &gt; 0:
        co2_spike_value *= co2_spike_decay
    elif random.random() &lt; co2_spike_chance:
        co2_spike_value = random.randint(*co2_spike_magnitude_range)
        co2_spike_decay = random.uniform(0.95, 0.99)
    co2 = co2_base + co2_spike_value + random.gauss(0, co2_noise_std)

    return temperature, humidity, co2</code></pre>
</details>
<div class="desc"><p>Generate advanced Indoor Air Quality (IAQ) data including temperature, humidity, and CO2 levels.
This method simulates IAQ data using sinusoidal patterns, diurnal adjustments, random noise,
and occasional CO2 spikes to mimic real-world environmental variations.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>device_id</code></strong> :&ensp;<code>str</code></dt>
<dd>The unique identifier for the device generating the data.</dd>
<dt><strong><code>did</code></strong> :&ensp;<code>str</code></dt>
<dd>Device ID or additional identifier for the data source.</dd>
<dt><strong><code>sensor_type</code></strong> :&ensp;<code>str</code></dt>
<dd>The type of sensor generating the data.</dd>
<dt><strong><code>start_time_str</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The starting timestamp for the simulation in the format
"YYYY-MM-DD HH:MM:SS". Defaults to "2024-12-27 00:00:00".</dd>
<dt><strong><code>temperature_base</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>The base temperature value in degrees Celsius. Defaults to 27.</dd>
<dt><strong><code>temperature_amplitude</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>The amplitude of the sinusoidal temperature variation. Defaults to 0.5.</dd>
<dt><strong><code>humidity_base</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>The base humidity value in percentage. Defaults to 50.</dd>
<dt><strong><code>humidity_amplitude</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>The amplitude of the sinusoidal humidity variation. Defaults to 0.5.</dd>
<dt><strong><code>co2_base</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The base CO2 level in ppm. Defaults to 500.</dd>
<dt><strong><code>co2_spike_chance</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>The probability of a CO2 spike occurring at each time step. Defaults to 0.01.</dd>
<dt><strong><code>co2_spike_magnitude_range</code></strong> :&ensp;<code>tuple</code>, optional</dt>
<dd>The range of CO2 spike magnitudes in ppm. Defaults to (300, 800).</dd>
<dt><strong><code>temperature_noise_std</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>The standard deviation of random noise added to temperature. Defaults to 0.05.</dd>
<dt><strong><code>humidity_noise_std</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>The standard deviation of random noise added to humidity. Defaults to 1.5.</dd>
<dt><strong><code>co2_noise_std</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>The standard deviation of random noise added to CO2 levels. Defaults to 20.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>A tuple containing:
- temperature (float): The simulated temperature value in degrees Celsius.
- humidity (float): The simulated humidity value in percentage.
- co2 (float): The simulated CO2 level in ppm.</dd>
</dl></div>
</dd>
<dt id="agent.IAQSensorSimulator.generate_iot_data"><code class="name flex">
<span>def <span class="ident">generate_iot_data</span></span>(<span>self, device_id, did, sensor_type) ‚Äë>¬†dict</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_iot_data(self, device_id, did, sensor_type) -&gt; dict:
    &#34;&#34;&#34;
    Generates IoT data for a given device based on the specified sensor type.
    Args:
        device_id (str): The unique identifier of the IoT device.
        did (str): The unique identifier for the data entry.
        sensor_type (str): The type of sensor data to generate. 
            Supported values are:
            - &#39;power_meter&#39;: Generates power meter data.
            - &#39;temperature&#39;: Generates temperature data.
            - &#39;humidity&#39;: Generates humidity data.
            - &#39;co2&#39;: Generates CO2 data.
            - &#39;online_status&#39;: Generates online status data.
            - &#39;occupancy_status&#39;: Generates occupancy status data.
            - &#39;sensitivity&#39;: Generates sensitivity data.
    Returns:
        dict: A dictionary containing the generated IoT data with the following keys:
            - &#34;datetime&#34; (str): The ISO 8601 formatted timestamp of the data.
            - &#34;id&#34; (str): The unique identifier for the data entry.
            - &#34;device_id&#34; (str): The unique identifier of the IoT device.
            - &#34;&lt;sensor_type&gt;&#34; (varies): The generated value for the specified sensor type.
            - &#34;sensor_type&#34; (str): The type of sensor data generated.
    Notes:
        - The method uses helper functions to generate specific types of data:
          `generate_iaq_data_advanced`, `generate_occupancy_data_advanced`, and 
          `generate_power_data_advanced`.
        - The `locals()` function is used to dynamically access the generated 
          sensor data based on the `sensor_type`.
    &#34;&#34;&#34;
    # NOTE: These variables are used in locals() to access the generated data
    temperature, humidity, co2 = self.generate_iaq_data_advanced()
    online_status, sensitivity, occupancy_status = self.generate_occupancy_data_advanced()
    power_meter = self.generate_power_data_advanced()
    if sensor_type == &#39;power_meter&#39;:
        return {
            &#34;datetime&#34;: self.current_time.isoformat(),
            &#39;id&#39;: did,
            &#34;device_id&#34;: device_id,
            &#34;power_meter&#34;: round(power_meter, 2),
            &#34;sensor_type&#34;: sensor_type
        }
    elif sensor_type in [&#39;temperature&#39;, &#39;humidity&#39;, &#39;co2&#39;]:
        return {
            &#34;datetime&#34;: self.current_time.isoformat(),
            &#34;id&#34;: did,
            &#34;device_id&#34;: device_id,
            sensor_type: round(locals()[sensor_type], 2),
            &#34;sensor_type&#34;: sensor_type
        }
    elif sensor_type in [&#39;online_status&#39;, &#39;occupancy_status&#39;, &#39;sensitivity&#39;]:
        return {
            &#34;datetime&#34;: self.current_time.isoformat(),
            &#34;id&#34;: did,
            &#34;device_id&#34;: device_id,
            sensor_type: locals()[sensor_type],
            &#34;sensor_type&#34;: sensor_type
        }</code></pre>
</details>
<div class="desc"><p>Generates IoT data for a given device based on the specified sensor type.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>device_id</code></strong> :&ensp;<code>str</code></dt>
<dd>The unique identifier of the IoT device.</dd>
<dt><strong><code>did</code></strong> :&ensp;<code>str</code></dt>
<dd>The unique identifier for the data entry.</dd>
<dt><strong><code>sensor_type</code></strong> :&ensp;<code>str</code></dt>
<dd>The type of sensor data to generate.
Supported values are:
- 'power_meter': Generates power meter data.
- 'temperature': Generates temperature data.
- 'humidity': Generates humidity data.
- 'co2': Generates CO2 data.
- 'online_status': Generates online status data.
- 'occupancy_status': Generates occupancy status data.
- 'sensitivity': Generates sensitivity data.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>A dictionary containing the generated IoT data with the following keys:
- "datetime" (str): The ISO 8601 formatted timestamp of the data.
- "id" (str): The unique identifier for the data entry.
- "device_id" (str): The unique identifier of the IoT device.
- "<sensor_type>" (varies): The generated value for the specified sensor type.
- "sensor_type" (str): The type of sensor data generated.</dd>
</dl>
<h2 id="notes">Notes</h2>
<ul>
<li>The method uses helper functions to generate specific types of data:
<code>generate_iaq_data_advanced</code>, <code>generate_occupancy_data_advanced</code>, and
<code>generate_power_data_advanced</code>.</li>
<li>The <code>locals()</code> function is used to dynamically access the generated
sensor data based on the <code>sensor_type</code>.</li>
</ul></div>
</dd>
<dt id="agent.IAQSensorSimulator.generate_occupancy_data_advanced"><code class="name flex">
<span>def <span class="ident">generate_occupancy_data_advanced</span></span>(<span>self) ‚Äë>¬†tuple</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_occupancy_data_advanced(self) -&gt; tuple:
    &#34;&#34;&#34;
    Generates advanced occupancy data for a given device.
    This method simulates the occupancy status, online status, and sensitivity 
    of a device based on the current time and random chance. It also introduces 
    a small probability of anomalies in the generated data.
    Args:
        device_id (str): The unique identifier of the device.
        did (str): The device ID used for internal processing.
        sensor_type (str): The type of sensor associated with the device.
    Returns:
        tuple: A tuple containing:
            - online_status (str): The online status of the device, either &#39;online&#39; or &#39;offline&#39;.
            - sensitivity (str): The sensitivity level of the device, represented as a percentage 
                (&#39;0%&#39;, &#39;25%&#39;, &#39;50%&#39;, &#39;75%&#39;, or &#39;100%&#39;).
            - occupancy_status (str): The occupancy status of the device, either &#39;occupied&#39; or &#39;unoccupied&#39;.
    &#34;&#34;&#34;
    current_time = self.current_time + self.interval_total_seconds * timedelta(seconds=1)
    if 0 &lt;= current_time.hour &lt; 6 or 12 &lt;= current_time.hour &lt; 18:
        occupancy_status = &#39;unoccupied&#39;
        occupancy_chance = random.random()
        if occupancy_chance &lt; 0.02:
            occupancy_status = &#39;occupied&#39;
    else:
        occupancy_status = &#39;occupied&#39;

    online_chance = random.random()
    if online_chance &lt; 0.02:
        online_status = &#39;offline&#39;
    else:
        online_status = &#39;online&#39;

    if online_status == &#39;offline&#39;:
        sensitivity = &#39;0%&#39;
    elif random.random() &gt; 0.02:
        sensitivity = &#39;100%&#39;
    else:
        sensitivity = random.choice([&#39;0%&#39;, &#39;25%&#39;, &#39;50%&#39;, &#39;75%&#39;])
    
    return online_status, sensitivity, occupancy_status</code></pre>
</details>
<div class="desc"><p>Generates advanced occupancy data for a given device.
This method simulates the occupancy status, online status, and sensitivity
of a device based on the current time and random chance. It also introduces
a small probability of anomalies in the generated data.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>device_id</code></strong> :&ensp;<code>str</code></dt>
<dd>The unique identifier of the device.</dd>
<dt><strong><code>did</code></strong> :&ensp;<code>str</code></dt>
<dd>The device ID used for internal processing.</dd>
<dt><strong><code>sensor_type</code></strong> :&ensp;<code>str</code></dt>
<dd>The type of sensor associated with the device.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>A tuple containing:
- online_status (str): The online status of the device, either 'online' or 'offline'.
- sensitivity (str): The sensitivity level of the device, represented as a percentage
('0%', '25%', '50%', '75%', or '100%').
- occupancy_status (str): The occupancy status of the device, either 'occupied' or 'unoccupied'.</dd>
</dl></div>
</dd>
<dt id="agent.IAQSensorSimulator.generate_power_data_advanced"><code class="name flex">
<span>def <span class="ident">generate_power_data_advanced</span></span>(<span>self) ‚Äë>¬†float</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_power_data_advanced(self) -&gt; float:
    &#34;&#34;&#34;
    Generates simulated power consumption data for a device with advanced features 
    such as random noise, base power, and occasional power spikes.
    Args:
        device_id (str): The unique identifier for the device.
        did (str): Additional identifier for the device (not used in the current implementation).
        sensor_type (str): The type of sensor associated with the device (not used in the current implementation).
    Returns:
        float: Simulated power consumption value in kilowatts (kW).
    Notes:
        - The base power consumption is randomly generated within a range of 0.1 to 2.5 kW.
        - Power spikes occur with a 10% probability and have a magnitude between 3 and 10 kW.
        - Power spikes decay over time with a random decay factor between 0.95 and 0.99.
        - Random Gaussian noise with a standard deviation of 0.1 kW is added to the final power value.
    &#34;&#34;&#34;
    power_spike_magnitude_range = (3, 10)  # kW
    power_base = random.uniform(0.1, 2.5)  # kW
    power_noise_std = 0.1  # kW
    power_spike_chance = random.random()
    power_spike_decay = random.uniform(0.95, 0.99)
    power_spike_value = 0

    if power_spike_value &gt; 0:
        power_spike_value *= power_spike_decay
    elif power_spike_chance &lt; 0.1:  # 10% chance of a spike
        power_spike_value = random.randint(*power_spike_magnitude_range)
        power_spike_decay = random.uniform(0.95, 0.99)

    power_meter = power_base + power_spike_value + random.gauss(0, power_noise_std)
    return power_meter</code></pre>
</details>
<div class="desc"><p>Generates simulated power consumption data for a device with advanced features
such as random noise, base power, and occasional power spikes.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>device_id</code></strong> :&ensp;<code>str</code></dt>
<dd>The unique identifier for the device.</dd>
<dt><strong><code>did</code></strong> :&ensp;<code>str</code></dt>
<dd>Additional identifier for the device (not used in the current implementation).</dd>
<dt><strong><code>sensor_type</code></strong> :&ensp;<code>str</code></dt>
<dd>The type of sensor associated with the device (not used in the current implementation).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>Simulated power consumption value in kilowatts (kW).</dd>
</dl>
<h2 id="notes">Notes</h2>
<ul>
<li>The base power consumption is randomly generated within a range of 0.1 to 2.5 kW.</li>
<li>Power spikes occur with a 10% probability and have a magnitude between 3 and 10 kW.</li>
<li>Power spikes decay over time with a random decay factor between 0.95 and 0.99.</li>
<li>Random Gaussian noise with a standard deviation of 0.1 kW is added to the final power value.</li>
</ul></div>
</dd>
<dt id="agent.IAQSensorSimulator.get_devices_from_supabase"><code class="name flex">
<span>def <span class="ident">get_devices_from_supabase</span></span>(<span>self) ‚Äë>¬†list</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_devices_from_supabase(self) -&gt; list:
    &#34;&#34;&#34;
    Fetches a list of devices from the Supabase database.

    This method queries the &#39;devices&#39; table in the Supabase database and retrieves
    all records. If devices are found, they are returned as a list. If no devices
    are found, an empty list is returned, and a message is printed to indicate this.

    Returns:
        list: A list of device records if found, otherwise an empty list.
    &#34;&#34;&#34;
    # Fetch devices from Supabase
    devices = self.supabase.table(&#39;devices&#39;).select(&#39;*&#39;).execute()
    if devices.data:
        return devices.data
    else:
        logging.info(&#34;No devices found in Supabase.&#34;)
        return []</code></pre>
</details>
<div class="desc"><p>Fetches a list of devices from the Supabase database.</p>
<p>This method queries the 'devices' table in the Supabase database and retrieves
all records. If devices are found, they are returned as a list. If no devices
are found, an empty list is returned, and a message is printed to indicate this.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code></dt>
<dd>A list of device records if found, otherwise an empty list.</dd>
</dl></div>
</dd>
<dt id="agent.IAQSensorSimulator.init_rabbitmq"><code class="name flex">
<span>async def <span class="ident">init_rabbitmq</span></span>(<span>self) ‚Äë>¬†None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def init_rabbitmq(self) -&gt; None:
    &#34;&#34;&#34;
    Initialize a connection to RabbitMQ using a robust connection and set up
    a communication channel with a durable topic exchange.

    This method establishes a robust connection to the RabbitMQ server using
    the provided RabbitMQ URL, creates a communication channel, and declares
    a durable topic exchange with the specified exchange name.
    &#34;&#34;&#34;
    self.connection = await connect_robust(self.RABBITMQ_URL)
    self.channel = await self.connection.channel()
    self.exchange = await self.channel.declare_exchange(
                        name=self.EXCHANGE_NAME,
                        type=&#39;topic&#39;,
                        durable=True
                    )</code></pre>
</details>
<div class="desc"><p>Initialize a connection to RabbitMQ using a robust connection and set up
a communication channel with a durable topic exchange.</p>
<p>This method establishes a robust connection to the RabbitMQ server using
the provided RabbitMQ URL, creates a communication channel, and declares
a durable topic exchange with the specified exchange name.</p></div>
</dd>
<dt id="agent.IAQSensorSimulator.publish_batch"><code class="name flex">
<span>async def <span class="ident">publish_batch</span></span>(<span>self, json_list) ‚Äë>¬†None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def publish_batch(self, json_list) -&gt; None:
    &#34;&#34;&#34;
    Publishes a batch of JSON messages to RabbitMQ queues based on sensor types.
    This asynchronous method connects to a RabbitMQ server, declares queues dynamically
    based on the `sensor_type` field in each message, binds the queues to an exchange,
    and publishes the messages to the appropriate queues.
    Args:
        json_list (list): A list of dictionaries, where each dictionary represents a 
                          JSON message containing a `sensor_type` key and other data.
    Raises:
        Exception: If there is an issue with connecting to RabbitMQ, declaring queues,
                   or publishing messages.
    Notes:
        - The RabbitMQ connection URL is retrieved from the `RABBITMQ_URL` environment variable.
        - The queues are declared as durable, ensuring they persist even if RabbitMQ restarts.
        - The messages are published with a delivery mode of 2, making them persistent.
        - The method uses asyncio to handle multiple tasks concurrently.
    &#34;&#34;&#34;
    connection = await connect_robust(self.RABBITMQ_URL)
    channel = await connection.channel()
    tasks = []
    for msg in json_list:
        sensor_type = msg[&#39;sensor_type&#39;]
        queue_name = f&#34;{sensor_type}_queue&#34;
        await channel.declare_queue(queue_name, durable=True)
        queue = await channel.declare_queue(queue_name, durable=True)
        await queue.bind(self.EXCHANGE_NAME, routing_key=queue_name)
        tasks.append(
            self.exchange.publish(
                Message(body=json.dumps(msg).encode(), delivery_mode=2),
                routing_key=queue_name
            )
        )

    await asyncio.gather(*tasks)
    await connection.close()</code></pre>
</details>
<div class="desc"><p>Publishes a batch of JSON messages to RabbitMQ queues based on sensor types.
This asynchronous method connects to a RabbitMQ server, declares queues dynamically
based on the <code>sensor_type</code> field in each message, binds the queues to an exchange,
and publishes the messages to the appropriate queues.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>json_list</code></strong> :&ensp;<code>list</code></dt>
<dd>A list of dictionaries, where each dictionary represents a
JSON message containing a <code>sensor_type</code> key and other data.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>Exception</code></dt>
<dd>If there is an issue with connecting to RabbitMQ, declaring queues,
or publishing messages.</dd>
</dl>
<h2 id="notes">Notes</h2>
<ul>
<li>The RabbitMQ connection URL is retrieved from the <code>RABBITMQ_URL</code> environment variable.</li>
<li>The queues are declared as durable, ensuring they persist even if RabbitMQ restarts.</li>
<li>The messages are published with a delivery mode of 2, making them persistent.</li>
<li>The method uses asyncio to handle multiple tasks concurrently.</li>
</ul></div>
</dd>
<dt id="agent.IAQSensorSimulator.publish_to_rabbitmq"><code class="name flex">
<span>def <span class="ident">publish_to_rabbitmq</span></span>(<span>self, data_list) ‚Äë>¬†None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def publish_to_rabbitmq(self, data_list) -&gt; None:
    &#34;&#34;&#34;
    Publishes a list of data to RabbitMQ with dynamically generated routing keys.
    This method processes a list of data dictionaries, determines the appropriate
    routing key for each data item based on its `sensor_type` and `device_id`, and
    publishes the data to a RabbitMQ exchange.
    Args:
        data_list (list): A list of dictionaries, where each dictionary represents
            a data item to be published. Each dictionary must contain the following keys:
            - &#39;device_id&#39; (str): The unique identifier of the device, formatted as a
              string with parts separated by hyphens.
            - &#39;sensor_type&#39; (str): The type of sensor (e.g., &#39;temperature&#39;, &#39;humidity&#39;,
              &#39;power_meter_...&#39;, etc.).
    Routing Key Generation:
        - For sensor types starting with &#39;power_meter_&#39;, the routing key suffix is &#34;POW&#34;.
        - For other sensor types, the suffix is determined by the `routing_key_map`.
        - If the sensor type is not found in the `routing_key_map`, the suffix defaults
          to &#34;UNKNOWN&#34;.
        - The final routing key is constructed by combining the first three parts of
          the `device_id` with the suffix, separated by hyphens.
    RabbitMQ Operations:
        - Declares a queue with the generated routing key.
        - Binds the queue to the specified exchange using the routing key.
        - Publishes the data to the exchange with the routing key.
    Raises:
        KeyError: If a required key (&#39;device_id&#39; or &#39;sensor_type&#39;) is missing from a
            data dictionary in the `data_list`.
        Exception: If there is an issue with RabbitMQ operations (e.g., queue declaration,
            binding, or publishing).
    Note:
        This method assumes that `self.channel` is a valid RabbitMQ channel and
        `self.EXCHANGE_NAME` is the name of the RabbitMQ exchange to publish to.
    &#34;&#34;&#34;
    routing_key_map = {
        &#39;temperature&#39;: &#39;IAQ&#39;,
        &#39;humidity&#39;: &#39;IAQ&#39;,
        &#39;co2&#39;: &#39;IAQ&#39;,
        &#39;online_status&#39;: &#39;OCC&#39;,
        &#39;occupancy_status&#39;: &#39;OCC&#39;,
        &#39;sensitivity&#39;: &#39;OCC&#39;
    }

    for data in data_list:
        device_id_parts = data[&#39;device_id&#39;].split(&#39;-&#39;)
        sensor_type = data[&#39;sensor_type&#39;]
        if sensor_type.startswith(&#39;power_meter_&#39;):
            routing_key_suffix = &#34;POW&#34;
        else:
            routing_key_suffix = routing_key_map.get(sensor_type, &#34;UNKNOWN&#34;)
        routing_key = &#39;-&#39;.join(device_id_parts[:3]) + f&#34;-{routing_key_suffix}&#34;
        self.channel.queue_declare(queue=routing_key)
        self.channel.queue_bind(exchange=self.EXCHANGE_NAME, queue=routing_key, routing_key=routing_key)
        self.channel.basic_publish(exchange=self.EXCHANGE_NAME, routing_key=routing_key, body=json.dumps(data))</code></pre>
</details>
<div class="desc"><p>Publishes a list of data to RabbitMQ with dynamically generated routing keys.
This method processes a list of data dictionaries, determines the appropriate
routing key for each data item based on its <code>sensor_type</code> and <code>device_id</code>, and
publishes the data to a RabbitMQ exchange.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data_list</code></strong> :&ensp;<code>list</code></dt>
<dd>A list of dictionaries, where each dictionary represents
a data item to be published. Each dictionary must contain the following keys:
- 'device_id' (str): The unique identifier of the device, formatted as a
string with parts separated by hyphens.
- 'sensor_type' (str): The type of sensor (e.g., 'temperature', 'humidity',
'power_meter_&hellip;', etc.).</dd>
</dl>
<p>Routing Key Generation:
- For sensor types starting with 'power_meter_', the routing key suffix is "POW".
- For other sensor types, the suffix is determined by the <code>routing_key_map</code>.
- If the sensor type is not found in the <code>routing_key_map</code>, the suffix defaults
to "UNKNOWN".
- The final routing key is constructed by combining the first three parts of
the <code>device_id</code> with the suffix, separated by hyphens.
RabbitMQ Operations:
- Declares a queue with the generated routing key.
- Binds the queue to the specified exchange using the routing key.
- Publishes the data to the exchange with the routing key.</p>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>KeyError</code></dt>
<dd>If a required key ('device_id' or 'sensor_type') is missing from a
data dictionary in the <code>data_list</code>.</dd>
<dt><code>Exception</code></dt>
<dd>If there is an issue with RabbitMQ operations (e.g., queue declaration,
binding, or publishing).</dd>
</dl>
<h2 id="note">Note</h2>
<p>This method assumes that <code>self.channel</code> is a valid RabbitMQ channel and
<code>self.EXCHANGE_NAME</code> is the name of the RabbitMQ exchange to publish to.</p></div>
</dd>
<dt id="agent.IAQSensorSimulator.publish_to_supabase"><code class="name flex">
<span>def <span class="ident">publish_to_supabase</span></span>(<span>self, data_list) ‚Äë>¬†None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def publish_to_supabase(self, data_list) -&gt; None:
    &#34;&#34;&#34;
    Publishes a list of sensor data to a Supabase table.

    This method transforms the input data into the required format and uploads it
    to the &#39;sensor_data_latest&#39; table in Supabase. The transformation includes
    mapping the input data to a dictionary with specific keys and converting the
    timestamp to a Unix timestamp.

    Args:
        data_list (list): A list of dictionaries, where each dictionary contains
            the following keys:
            - &#39;device_id&#39; (str): The unique identifier of the device.
            - &#39;sensor_type&#39; (str): The type of sensor (e.g., temperature, humidity).
            - &#39;datetime&#39; (str): The ISO 8601 formatted datetime string.
            - &#39;id&#39; (int): The unique identifier for the data point.
            - A key matching the value of &#39;sensor_type&#39; (e.g., &#39;temperature&#39;): The
              sensor reading value.

    Raises:
        ValueError: If the &#39;datetime&#39; field in the input data cannot be parsed
            into a valid datetime object.

    Notes:
        - The &#39;timestamp&#39; field is derived from the &#39;datetime&#39; field and is stored
          as a Unix timestamp.
        - The &#39;did&#39; field is derived from the &#39;id&#39; field and is stored as an integer.
        - The &#39;upsert&#39; operation ensures that existing records with the same
          &#39;device_id&#39; and &#39;datapoint&#39; are updated, while new records are inserted.
    &#34;&#34;&#34;
    # transform data_list to a list of dictionaries with the required keys to match the Supabase table
    data_list = list(map(lambda x: {
        &#39;device_id&#39;: x[&#39;device_id&#39;],
        &#39;datapoint&#39;: x[&#39;sensor_type&#39;],
        &#39;value&#39;: x[x[&#39;sensor_type&#39;]],
        &#39;timestamp&#39;: int(datetime.fromisoformat(x[&#39;datetime&#39;]).timestamp()),
        &#39;datetime&#39;: x[&#39;datetime&#39;],
        &#39;did&#39;: int(x[&#39;id&#39;])}, data_list))
    self.supabase.table(&#39;sensor_data_latest&#39;).upsert(data_list, on_conflict=&#39;device_id, datapoint&#39;).execute()</code></pre>
</details>
<div class="desc"><p>Publishes a list of sensor data to a Supabase table.</p>
<p>This method transforms the input data into the required format and uploads it
to the 'sensor_data_latest' table in Supabase. The transformation includes
mapping the input data to a dictionary with specific keys and converting the
timestamp to a Unix timestamp.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data_list</code></strong> :&ensp;<code>list</code></dt>
<dd>A list of dictionaries, where each dictionary contains
the following keys:
- 'device_id' (str): The unique identifier of the device.
- 'sensor_type' (str): The type of sensor (e.g., temperature, humidity).
- 'datetime' (str): The ISO 8601 formatted datetime string.
- 'id' (int): The unique identifier for the data point.
- A key matching the value of 'sensor_type' (e.g., 'temperature'): The
sensor reading value.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If the 'datetime' field in the input data cannot be parsed
into a valid datetime object.</dd>
</dl>
<h2 id="notes">Notes</h2>
<ul>
<li>The 'timestamp' field is derived from the 'datetime' field and is stored
as a Unix timestamp.</li>
<li>The 'did' field is derived from the 'id' field and is stored as an integer.</li>
<li>The 'upsert' operation ensures that existing records with the same
'device_id' and 'datapoint' are updated, while new records are inserted.</li>
</ul></div>
</dd>
<dt id="agent.IAQSensorSimulator.run_simulation"><code class="name flex">
<span>async def <span class="ident">run_simulation</span></span>(<span>self) ‚Äë>¬†None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def run_simulation(self) -&gt; None:
    &#34;&#34;&#34;
    Runs the IAQ (Indoor Air Quality) Sensor Simulator.
    This asynchronous method initializes RabbitMQ, retrieves devices from Supabase, 
    generates IoT data for each device, and publishes the data to both Supabase 
    and RabbitMQ in batches. The simulation runs for a specified number of entries 
    or until interrupted.
    &#34;&#34;&#34;
    logging.basicConfig(level=logging.INFO, format=&#39;%(asctime)s - %(levelname)s - %(message)s&#39;)
    # Silence Supabase Realtime logs
    logging.getLogger(&#34;pika&#34;).setLevel(logging.WARNING)
    logging.getLogger(&#39;realtime&#39;).setLevel(logging.WARNING)
    logging.getLogger(&#39;realtime._async.client&#39;).setLevel(logging.WARNING)
    logging.getLogger(&#39;realtime._async.channel&#39;).setLevel(logging.WARNING)
    # Optionally, silence other related loggers
    logging.getLogger(&#39;httpx&#39;).setLevel(logging.WARNING)
    logging.getLogger(&#39;asyncio&#39;).setLevel(logging.WARNING)
    logging.getLogger(&#39;phx_websocket&#39;).setLevel(logging.WARNING)
    logging.getLogger(&#39;phoenix&#39;).setLevel(logging.WARNING)
    logging.getLogger(&#39;websockets&#39;).setLevel(logging.WARNING)

    logging.info(&#34;ü§ñ IAQ Sensor Simulator started.&#34;)
    logging.info(&#34;ü§ñ RabbitMQ dashboard available at: http://localhost:15672&#34;)
    get_devices = self.get_devices_from_supabase()
    await self.init_rabbitmq()

    try:
        max_entries = config(&#39;MAX_ENTRIES&#39;, default=1000, cast=int)
        for _ in range(max_entries):
            iaq_data_list = list(map(
                lambda d: self.generate_iot_data(d[&#39;device_identifier&#39;], d[&#39;id&#39;], d[&#39;sensor_type&#39;]),
                get_devices
            ))
            iaq_data_list = list(filter(None, iaq_data_list))
            self.publish_to_supabase(iaq_data_list)
            await self.publish_batch(iaq_data_list)
            self.current_time = datetime.now()
            await asyncio.sleep(self.interval_seconds)

    except KeyboardInterrupt:
        logging.info(&#34;IAQ Sensor Simulator stopped.&#34;)
    except Exception as e:
        logging.error(f&#34;Simulation error: {e}&#34;)
    finally:
        await self.close_rabbitmq()
        logging.info(&#34;Cleanup done. Bye!&#34;)</code></pre>
</details>
<div class="desc"><p>Runs the IAQ (Indoor Air Quality) Sensor Simulator.
This asynchronous method initializes RabbitMQ, retrieves devices from Supabase,
generates IoT data for each device, and publishes the data to both Supabase
and RabbitMQ in batches. The simulation runs for a specified number of entries
or until interrupted.</p></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
<ul>
<li><code><a title="agent.agent_fault_detection" href="agent_fault_detection.html">agent.agent_fault_detection</a></code></li>
<li><code><a title="agent.agent_simulation" href="agent_simulation.html">agent.agent_simulation</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="agent.FaultDetectionAgent" href="#agent.FaultDetectionAgent">FaultDetectionAgent</a></code></h4>
<ul class="">
<li><code><a title="agent.FaultDetectionAgent.detect_faults" href="#agent.FaultDetectionAgent.detect_faults">detect_faults</a></code></li>
<li><code><a title="agent.FaultDetectionAgent.get_default_thresholds" href="#agent.FaultDetectionAgent.get_default_thresholds">get_default_thresholds</a></code></li>
<li><code><a title="agent.FaultDetectionAgent.get_initial_thresholds" href="#agent.FaultDetectionAgent.get_initial_thresholds">get_initial_thresholds</a></code></li>
<li><code><a title="agent.FaultDetectionAgent.get_queues_for_exchange" href="#agent.FaultDetectionAgent.get_queues_for_exchange">get_queues_for_exchange</a></code></li>
<li><code><a title="agent.FaultDetectionAgent.init_db_connection" href="#agent.FaultDetectionAgent.init_db_connection">init_db_connection</a></code></li>
<li><code><a title="agent.FaultDetectionAgent.init_rabbitmq_connection" href="#agent.FaultDetectionAgent.init_rabbitmq_connection">init_rabbitmq_connection</a></code></li>
<li><code><a title="agent.FaultDetectionAgent.insert_row_data" href="#agent.FaultDetectionAgent.insert_row_data">insert_row_data</a></code></li>
<li><code><a title="agent.FaultDetectionAgent.process_and_insert_data" href="#agent.FaultDetectionAgent.process_and_insert_data">process_and_insert_data</a></code></li>
<li><code><a title="agent.FaultDetectionAgent.process_threshold_data" href="#agent.FaultDetectionAgent.process_threshold_data">process_threshold_data</a></code></li>
<li><code><a title="agent.FaultDetectionAgent.publish_alert" href="#agent.FaultDetectionAgent.publish_alert">publish_alert</a></code></li>
<li><code><a title="agent.FaultDetectionAgent.publish_to_rabbitmq" href="#agent.FaultDetectionAgent.publish_to_rabbitmq">publish_to_rabbitmq</a></code></li>
<li><code><a title="agent.FaultDetectionAgent.publish_to_supabase" href="#agent.FaultDetectionAgent.publish_to_supabase">publish_to_supabase</a></code></li>
<li><code><a title="agent.FaultDetectionAgent.run_fault_detection" href="#agent.FaultDetectionAgent.run_fault_detection">run_fault_detection</a></code></li>
<li><code><a title="agent.FaultDetectionAgent.setup_realtime_subscription" href="#agent.FaultDetectionAgent.setup_realtime_subscription">setup_realtime_subscription</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="agent.IAQSensorSimulator" href="#agent.IAQSensorSimulator">IAQSensorSimulator</a></code></h4>
<ul class="">
<li><code><a title="agent.IAQSensorSimulator.close_rabbitmq" href="#agent.IAQSensorSimulator.close_rabbitmq">close_rabbitmq</a></code></li>
<li><code><a title="agent.IAQSensorSimulator.generate_iaq_data_advanced" href="#agent.IAQSensorSimulator.generate_iaq_data_advanced">generate_iaq_data_advanced</a></code></li>
<li><code><a title="agent.IAQSensorSimulator.generate_iot_data" href="#agent.IAQSensorSimulator.generate_iot_data">generate_iot_data</a></code></li>
<li><code><a title="agent.IAQSensorSimulator.generate_occupancy_data_advanced" href="#agent.IAQSensorSimulator.generate_occupancy_data_advanced">generate_occupancy_data_advanced</a></code></li>
<li><code><a title="agent.IAQSensorSimulator.generate_power_data_advanced" href="#agent.IAQSensorSimulator.generate_power_data_advanced">generate_power_data_advanced</a></code></li>
<li><code><a title="agent.IAQSensorSimulator.get_devices_from_supabase" href="#agent.IAQSensorSimulator.get_devices_from_supabase">get_devices_from_supabase</a></code></li>
<li><code><a title="agent.IAQSensorSimulator.init_rabbitmq" href="#agent.IAQSensorSimulator.init_rabbitmq">init_rabbitmq</a></code></li>
<li><code><a title="agent.IAQSensorSimulator.publish_batch" href="#agent.IAQSensorSimulator.publish_batch">publish_batch</a></code></li>
<li><code><a title="agent.IAQSensorSimulator.publish_to_rabbitmq" href="#agent.IAQSensorSimulator.publish_to_rabbitmq">publish_to_rabbitmq</a></code></li>
<li><code><a title="agent.IAQSensorSimulator.publish_to_supabase" href="#agent.IAQSensorSimulator.publish_to_supabase">publish_to_supabase</a></code></li>
<li><code><a title="agent.IAQSensorSimulator.run_simulation" href="#agent.IAQSensorSimulator.run_simulation">run_simulation</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
